{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy import stats\n",
    "from sklearn.metrics import explained_variance_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date         datetime  SPOSTMIN  SACTMIN DAYOFWEEK\n",
      "0        6/4/2013    6/4/2013 9:00      30.0      NaN   Tuesday\n",
      "1        6/4/2013    6/4/2013 9:30      30.0      NaN   Tuesday\n",
      "2        6/4/2013   6/4/2013 10:00      60.0      NaN   Tuesday\n",
      "3        6/4/2013   6/4/2013 10:30      60.0      NaN   Tuesday\n",
      "4        6/4/2013   6/4/2013 11:00      60.0      NaN   Tuesday\n",
      "5        6/4/2013   6/4/2013 11:30      90.0      NaN   Tuesday\n",
      "6        6/4/2013   6/4/2013 12:00      90.0      NaN   Tuesday\n",
      "7        6/4/2013   6/4/2013 13:00     120.0      NaN   Tuesday\n",
      "8        6/4/2013   6/4/2013 13:30     120.0      NaN   Tuesday\n",
      "9        6/4/2013   6/4/2013 14:00      90.0      NaN   Tuesday\n",
      "10       6/4/2013   6/4/2013 15:00      90.0      NaN   Tuesday\n",
      "11       6/4/2013   6/4/2013 15:30      90.0      NaN   Tuesday\n",
      "12       6/4/2013   6/4/2013 16:00      90.0      NaN   Tuesday\n",
      "13       6/4/2013   6/4/2013 16:00      90.0      NaN   Tuesday\n",
      "14       6/4/2013   6/4/2013 16:30     120.0      NaN   Tuesday\n",
      "15       6/4/2013   6/4/2013 17:00      90.0      NaN   Tuesday\n",
      "16       6/4/2013   6/4/2013 17:30     100.0      NaN   Tuesday\n",
      "17       6/4/2013   6/4/2013 18:00      90.0      NaN   Tuesday\n",
      "18       6/4/2013   6/4/2013 18:30     120.0      NaN   Tuesday\n",
      "19       6/4/2013   6/4/2013 19:00      90.0      NaN   Tuesday\n",
      "20       6/4/2013   6/4/2013 19:30      90.0      NaN   Tuesday\n",
      "21       6/4/2013   6/4/2013 20:00     100.0      NaN   Tuesday\n",
      "22       6/4/2013   6/4/2013 20:00      90.0      NaN   Tuesday\n",
      "23       6/4/2013   6/4/2013 20:30      60.0      NaN   Tuesday\n",
      "24       6/4/2013   6/4/2013 21:00      60.0      NaN   Tuesday\n",
      "25      5/23/2014   5/23/2014 7:12     120.0      NaN    Friday\n",
      "26      5/23/2014   5/23/2014 7:21      35.0      NaN    Friday\n",
      "27      5/23/2014   5/23/2014 7:32      90.0      NaN    Friday\n",
      "28      5/23/2014   5/23/2014 7:35      90.0      NaN    Friday\n",
      "29      5/23/2014   5/23/2014 7:45      60.0      NaN    Friday\n",
      "...           ...              ...       ...      ...       ...\n",
      "243898  3/31/2019  3/31/2019 19:35      90.0      NaN    Sunday\n",
      "243899  3/31/2019  3/31/2019 19:42      90.0      NaN    Sunday\n",
      "243900  3/31/2019  3/31/2019 19:49      85.0      NaN    Sunday\n",
      "243901  3/31/2019  3/31/2019 19:56      85.0      NaN    Sunday\n",
      "243902  3/31/2019  3/31/2019 20:00      85.0      NaN    Sunday\n",
      "243903  3/31/2019  3/31/2019 20:07      90.0      NaN    Sunday\n",
      "243904  3/31/2019  3/31/2019 20:14      90.0      NaN    Sunday\n",
      "243905  3/31/2019  3/31/2019 20:21      90.0      NaN    Sunday\n",
      "243906  3/31/2019  3/31/2019 20:27      85.0      NaN    Sunday\n",
      "243907  3/31/2019  3/31/2019 20:35      85.0      NaN    Sunday\n",
      "243908  3/31/2019  3/31/2019 20:42      85.0      NaN    Sunday\n",
      "243909  3/31/2019  3/31/2019 20:49      80.0      NaN    Sunday\n",
      "243910  3/31/2019  3/31/2019 20:56      80.0      NaN    Sunday\n",
      "243911  3/31/2019  3/31/2019 21:00      80.0      NaN    Sunday\n",
      "243912  3/31/2019  3/31/2019 21:07      75.0      NaN    Sunday\n",
      "243913  3/31/2019  3/31/2019 21:14      30.0      NaN    Sunday\n",
      "243914  3/31/2019  3/31/2019 21:21      30.0      NaN    Sunday\n",
      "243915  3/31/2019  3/31/2019 21:27      40.0      NaN    Sunday\n",
      "243916  3/31/2019  3/31/2019 21:35      40.0      NaN    Sunday\n",
      "243917  3/31/2019  3/31/2019 21:42      40.0      NaN    Sunday\n",
      "243918  3/31/2019  3/31/2019 21:47      55.0      NaN    Sunday\n",
      "243919  3/31/2019  3/31/2019 21:49      55.0      NaN    Sunday\n",
      "243920  3/31/2019  3/31/2019 21:56      45.0      NaN    Sunday\n",
      "243921  3/31/2019  3/31/2019 22:00      35.0      NaN    Sunday\n",
      "243922  3/31/2019  3/31/2019 22:07    -999.0      NaN    Sunday\n",
      "243923  3/31/2019  3/31/2019 22:14    -999.0      NaN    Sunday\n",
      "243924  3/31/2019  3/31/2019 22:21    -999.0      NaN    Sunday\n",
      "243925  3/31/2019  3/31/2019 22:27    -999.0      NaN    Sunday\n",
      "243926  3/31/2019  3/31/2019 22:35    -999.0      NaN    Sunday\n",
      "243927  3/31/2019  3/31/2019 22:42    -999.0      NaN    Sunday\n",
      "\n",
      "[243928 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df_initial = pd.read_csv('7_dwarfs_train.csv')\n",
    "print(df_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date              6/4/2013\n",
      "datetime     6/4/2013 9:00\n",
      "SPOSTMIN                30\n",
      "SACTMIN                NaN\n",
      "DAYOFWEEK          Tuesday\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_initial.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(df_initial.loc[0]['SACTMIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_initial.loc[0]['datetime']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_initial.iterrows():\n",
    "    if math.isnan(row['SPOSTMIN']):\n",
    "        df_initial.loc[index,'SPOSTMIN'] = df_initial.loc[index, 'SACTMIN']\n",
    "#     print(row['SPOSTMIN'], row['SACTMIN'])\n",
    "df_initial = df_initial.drop(columns=\"SACTMIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial = df_initial[df_initial['SPOSTMIN'] != -999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date         datetime  SPOSTMIN DAYOFWEEK\n",
      "0        6/4/2013    6/4/2013 9:00      30.0   Tuesday\n",
      "1        6/4/2013    6/4/2013 9:30      30.0   Tuesday\n",
      "2        6/4/2013   6/4/2013 10:00      60.0   Tuesday\n",
      "3        6/4/2013   6/4/2013 10:30      60.0   Tuesday\n",
      "4        6/4/2013   6/4/2013 11:00      60.0   Tuesday\n",
      "5        6/4/2013   6/4/2013 11:30      90.0   Tuesday\n",
      "6        6/4/2013   6/4/2013 12:00      90.0   Tuesday\n",
      "7        6/4/2013   6/4/2013 13:00     120.0   Tuesday\n",
      "8        6/4/2013   6/4/2013 13:30     120.0   Tuesday\n",
      "9        6/4/2013   6/4/2013 14:00      90.0   Tuesday\n",
      "10       6/4/2013   6/4/2013 15:00      90.0   Tuesday\n",
      "11       6/4/2013   6/4/2013 15:30      90.0   Tuesday\n",
      "12       6/4/2013   6/4/2013 16:00      90.0   Tuesday\n",
      "13       6/4/2013   6/4/2013 16:00      90.0   Tuesday\n",
      "14       6/4/2013   6/4/2013 16:30     120.0   Tuesday\n",
      "15       6/4/2013   6/4/2013 17:00      90.0   Tuesday\n",
      "16       6/4/2013   6/4/2013 17:30     100.0   Tuesday\n",
      "17       6/4/2013   6/4/2013 18:00      90.0   Tuesday\n",
      "18       6/4/2013   6/4/2013 18:30     120.0   Tuesday\n",
      "19       6/4/2013   6/4/2013 19:00      90.0   Tuesday\n",
      "20       6/4/2013   6/4/2013 19:30      90.0   Tuesday\n",
      "21       6/4/2013   6/4/2013 20:00     100.0   Tuesday\n",
      "22       6/4/2013   6/4/2013 20:00      90.0   Tuesday\n",
      "23       6/4/2013   6/4/2013 20:30      60.0   Tuesday\n",
      "24       6/4/2013   6/4/2013 21:00      60.0   Tuesday\n",
      "25      5/23/2014   5/23/2014 7:12     120.0    Friday\n",
      "26      5/23/2014   5/23/2014 7:21      35.0    Friday\n",
      "27      5/23/2014   5/23/2014 7:32      90.0    Friday\n",
      "28      5/23/2014   5/23/2014 7:35      90.0    Friday\n",
      "29      5/23/2014   5/23/2014 7:45      60.0    Friday\n",
      "...           ...              ...       ...       ...\n",
      "243892  3/31/2019  3/31/2019 18:56      90.0    Sunday\n",
      "243893  3/31/2019  3/31/2019 19:00      90.0    Sunday\n",
      "243894  3/31/2019  3/31/2019 19:07      90.0    Sunday\n",
      "243895  3/31/2019  3/31/2019 19:14      90.0    Sunday\n",
      "243896  3/31/2019  3/31/2019 19:21      90.0    Sunday\n",
      "243897  3/31/2019  3/31/2019 19:27      90.0    Sunday\n",
      "243898  3/31/2019  3/31/2019 19:35      90.0    Sunday\n",
      "243899  3/31/2019  3/31/2019 19:42      90.0    Sunday\n",
      "243900  3/31/2019  3/31/2019 19:49      85.0    Sunday\n",
      "243901  3/31/2019  3/31/2019 19:56      85.0    Sunday\n",
      "243902  3/31/2019  3/31/2019 20:00      85.0    Sunday\n",
      "243903  3/31/2019  3/31/2019 20:07      90.0    Sunday\n",
      "243904  3/31/2019  3/31/2019 20:14      90.0    Sunday\n",
      "243905  3/31/2019  3/31/2019 20:21      90.0    Sunday\n",
      "243906  3/31/2019  3/31/2019 20:27      85.0    Sunday\n",
      "243907  3/31/2019  3/31/2019 20:35      85.0    Sunday\n",
      "243908  3/31/2019  3/31/2019 20:42      85.0    Sunday\n",
      "243909  3/31/2019  3/31/2019 20:49      80.0    Sunday\n",
      "243910  3/31/2019  3/31/2019 20:56      80.0    Sunday\n",
      "243911  3/31/2019  3/31/2019 21:00      80.0    Sunday\n",
      "243912  3/31/2019  3/31/2019 21:07      75.0    Sunday\n",
      "243913  3/31/2019  3/31/2019 21:14      30.0    Sunday\n",
      "243914  3/31/2019  3/31/2019 21:21      30.0    Sunday\n",
      "243915  3/31/2019  3/31/2019 21:27      40.0    Sunday\n",
      "243916  3/31/2019  3/31/2019 21:35      40.0    Sunday\n",
      "243917  3/31/2019  3/31/2019 21:42      40.0    Sunday\n",
      "243918  3/31/2019  3/31/2019 21:47      55.0    Sunday\n",
      "243919  3/31/2019  3/31/2019 21:49      55.0    Sunday\n",
      "243920  3/31/2019  3/31/2019 21:56      45.0    Sunday\n",
      "243921  3/31/2019  3/31/2019 22:00      35.0    Sunday\n",
      "\n",
      "[227645 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial['Month'] = df_initial.date.str.split('/').str[0]\n",
    "df_initial['Day'] = df_initial.date.str.split('/').str[1]\n",
    "df_initial['Year'] = df_initial.date.str.rsplit('/', 1).str[1]\n",
    "df_initial['Time_char'] = df_initial.datetime.str.split(' ').str[1]\n",
    "df_initial['Hour'] = df_initial['Time_char'].str.split(':').str[0]\n",
    "df_initial['Minute'] = df_initial['Time_char'].str.split(':').str[1]\n",
    "df_initial = df_initial.drop(columns=\"Time_char\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date         datetime  SPOSTMIN DAYOFWEEK Month Day  Year Hour  \\\n",
      "0        6/4/2013    6/4/2013 9:00      30.0   Tuesday     6   4  2013    9   \n",
      "1        6/4/2013    6/4/2013 9:30      30.0   Tuesday     6   4  2013    9   \n",
      "2        6/4/2013   6/4/2013 10:00      60.0   Tuesday     6   4  2013   10   \n",
      "3        6/4/2013   6/4/2013 10:30      60.0   Tuesday     6   4  2013   10   \n",
      "4        6/4/2013   6/4/2013 11:00      60.0   Tuesday     6   4  2013   11   \n",
      "5        6/4/2013   6/4/2013 11:30      90.0   Tuesday     6   4  2013   11   \n",
      "6        6/4/2013   6/4/2013 12:00      90.0   Tuesday     6   4  2013   12   \n",
      "7        6/4/2013   6/4/2013 13:00     120.0   Tuesday     6   4  2013   13   \n",
      "8        6/4/2013   6/4/2013 13:30     120.0   Tuesday     6   4  2013   13   \n",
      "9        6/4/2013   6/4/2013 14:00      90.0   Tuesday     6   4  2013   14   \n",
      "10       6/4/2013   6/4/2013 15:00      90.0   Tuesday     6   4  2013   15   \n",
      "11       6/4/2013   6/4/2013 15:30      90.0   Tuesday     6   4  2013   15   \n",
      "12       6/4/2013   6/4/2013 16:00      90.0   Tuesday     6   4  2013   16   \n",
      "13       6/4/2013   6/4/2013 16:00      90.0   Tuesday     6   4  2013   16   \n",
      "14       6/4/2013   6/4/2013 16:30     120.0   Tuesday     6   4  2013   16   \n",
      "15       6/4/2013   6/4/2013 17:00      90.0   Tuesday     6   4  2013   17   \n",
      "16       6/4/2013   6/4/2013 17:30     100.0   Tuesday     6   4  2013   17   \n",
      "17       6/4/2013   6/4/2013 18:00      90.0   Tuesday     6   4  2013   18   \n",
      "18       6/4/2013   6/4/2013 18:30     120.0   Tuesday     6   4  2013   18   \n",
      "19       6/4/2013   6/4/2013 19:00      90.0   Tuesday     6   4  2013   19   \n",
      "20       6/4/2013   6/4/2013 19:30      90.0   Tuesday     6   4  2013   19   \n",
      "21       6/4/2013   6/4/2013 20:00     100.0   Tuesday     6   4  2013   20   \n",
      "22       6/4/2013   6/4/2013 20:00      90.0   Tuesday     6   4  2013   20   \n",
      "23       6/4/2013   6/4/2013 20:30      60.0   Tuesday     6   4  2013   20   \n",
      "24       6/4/2013   6/4/2013 21:00      60.0   Tuesday     6   4  2013   21   \n",
      "25      5/23/2014   5/23/2014 7:12     120.0    Friday     5  23  2014    7   \n",
      "26      5/23/2014   5/23/2014 7:21      35.0    Friday     5  23  2014    7   \n",
      "27      5/23/2014   5/23/2014 7:32      90.0    Friday     5  23  2014    7   \n",
      "28      5/23/2014   5/23/2014 7:35      90.0    Friday     5  23  2014    7   \n",
      "29      5/23/2014   5/23/2014 7:45      60.0    Friday     5  23  2014    7   \n",
      "...           ...              ...       ...       ...   ...  ..   ...  ...   \n",
      "243892  3/31/2019  3/31/2019 18:56      90.0    Sunday     3  31  2019   18   \n",
      "243893  3/31/2019  3/31/2019 19:00      90.0    Sunday     3  31  2019   19   \n",
      "243894  3/31/2019  3/31/2019 19:07      90.0    Sunday     3  31  2019   19   \n",
      "243895  3/31/2019  3/31/2019 19:14      90.0    Sunday     3  31  2019   19   \n",
      "243896  3/31/2019  3/31/2019 19:21      90.0    Sunday     3  31  2019   19   \n",
      "243897  3/31/2019  3/31/2019 19:27      90.0    Sunday     3  31  2019   19   \n",
      "243898  3/31/2019  3/31/2019 19:35      90.0    Sunday     3  31  2019   19   \n",
      "243899  3/31/2019  3/31/2019 19:42      90.0    Sunday     3  31  2019   19   \n",
      "243900  3/31/2019  3/31/2019 19:49      85.0    Sunday     3  31  2019   19   \n",
      "243901  3/31/2019  3/31/2019 19:56      85.0    Sunday     3  31  2019   19   \n",
      "243902  3/31/2019  3/31/2019 20:00      85.0    Sunday     3  31  2019   20   \n",
      "243903  3/31/2019  3/31/2019 20:07      90.0    Sunday     3  31  2019   20   \n",
      "243904  3/31/2019  3/31/2019 20:14      90.0    Sunday     3  31  2019   20   \n",
      "243905  3/31/2019  3/31/2019 20:21      90.0    Sunday     3  31  2019   20   \n",
      "243906  3/31/2019  3/31/2019 20:27      85.0    Sunday     3  31  2019   20   \n",
      "243907  3/31/2019  3/31/2019 20:35      85.0    Sunday     3  31  2019   20   \n",
      "243908  3/31/2019  3/31/2019 20:42      85.0    Sunday     3  31  2019   20   \n",
      "243909  3/31/2019  3/31/2019 20:49      80.0    Sunday     3  31  2019   20   \n",
      "243910  3/31/2019  3/31/2019 20:56      80.0    Sunday     3  31  2019   20   \n",
      "243911  3/31/2019  3/31/2019 21:00      80.0    Sunday     3  31  2019   21   \n",
      "243912  3/31/2019  3/31/2019 21:07      75.0    Sunday     3  31  2019   21   \n",
      "243913  3/31/2019  3/31/2019 21:14      30.0    Sunday     3  31  2019   21   \n",
      "243914  3/31/2019  3/31/2019 21:21      30.0    Sunday     3  31  2019   21   \n",
      "243915  3/31/2019  3/31/2019 21:27      40.0    Sunday     3  31  2019   21   \n",
      "243916  3/31/2019  3/31/2019 21:35      40.0    Sunday     3  31  2019   21   \n",
      "243917  3/31/2019  3/31/2019 21:42      40.0    Sunday     3  31  2019   21   \n",
      "243918  3/31/2019  3/31/2019 21:47      55.0    Sunday     3  31  2019   21   \n",
      "243919  3/31/2019  3/31/2019 21:49      55.0    Sunday     3  31  2019   21   \n",
      "243920  3/31/2019  3/31/2019 21:56      45.0    Sunday     3  31  2019   21   \n",
      "243921  3/31/2019  3/31/2019 22:00      35.0    Sunday     3  31  2019   22   \n",
      "\n",
      "       Minute  \n",
      "0          00  \n",
      "1          30  \n",
      "2          00  \n",
      "3          30  \n",
      "4          00  \n",
      "5          30  \n",
      "6          00  \n",
      "7          00  \n",
      "8          30  \n",
      "9          00  \n",
      "10         00  \n",
      "11         30  \n",
      "12         00  \n",
      "13         00  \n",
      "14         30  \n",
      "15         00  \n",
      "16         30  \n",
      "17         00  \n",
      "18         30  \n",
      "19         00  \n",
      "20         30  \n",
      "21         00  \n",
      "22         00  \n",
      "23         30  \n",
      "24         00  \n",
      "25         12  \n",
      "26         21  \n",
      "27         32  \n",
      "28         35  \n",
      "29         45  \n",
      "...       ...  \n",
      "243892     56  \n",
      "243893     00  \n",
      "243894     07  \n",
      "243895     14  \n",
      "243896     21  \n",
      "243897     27  \n",
      "243898     35  \n",
      "243899     42  \n",
      "243900     49  \n",
      "243901     56  \n",
      "243902     00  \n",
      "243903     07  \n",
      "243904     14  \n",
      "243905     21  \n",
      "243906     27  \n",
      "243907     35  \n",
      "243908     42  \n",
      "243909     49  \n",
      "243910     56  \n",
      "243911     00  \n",
      "243912     07  \n",
      "243913     14  \n",
      "243914     21  \n",
      "243915     27  \n",
      "243916     35  \n",
      "243917     42  \n",
      "243918     47  \n",
      "243919     49  \n",
      "243920     56  \n",
      "243921     00  \n",
      "\n",
      "[227645 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial['Month'] = (df_initial['Month']).astype(int)\n",
    "df_initial['Day'] = (df_initial['Day']).astype(int)\n",
    "df_initial['Year'] = (df_initial['Year']).astype(int)\n",
    "df_initial['Hour'] = (df_initial['Hour']).astype(int)\n",
    "df_initial['Minute'] = (df_initial['Minute']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date         datetime  SPOSTMIN DAYOFWEEK  Month  Day  Year  \\\n",
      "0        6/4/2013    6/4/2013 9:00      30.0   Tuesday      6    4  2013   \n",
      "1        6/4/2013    6/4/2013 9:30      30.0   Tuesday      6    4  2013   \n",
      "2        6/4/2013   6/4/2013 10:00      60.0   Tuesday      6    4  2013   \n",
      "3        6/4/2013   6/4/2013 10:30      60.0   Tuesday      6    4  2013   \n",
      "4        6/4/2013   6/4/2013 11:00      60.0   Tuesday      6    4  2013   \n",
      "5        6/4/2013   6/4/2013 11:30      90.0   Tuesday      6    4  2013   \n",
      "6        6/4/2013   6/4/2013 12:00      90.0   Tuesday      6    4  2013   \n",
      "7        6/4/2013   6/4/2013 13:00     120.0   Tuesday      6    4  2013   \n",
      "8        6/4/2013   6/4/2013 13:30     120.0   Tuesday      6    4  2013   \n",
      "9        6/4/2013   6/4/2013 14:00      90.0   Tuesday      6    4  2013   \n",
      "10       6/4/2013   6/4/2013 15:00      90.0   Tuesday      6    4  2013   \n",
      "11       6/4/2013   6/4/2013 15:30      90.0   Tuesday      6    4  2013   \n",
      "12       6/4/2013   6/4/2013 16:00      90.0   Tuesday      6    4  2013   \n",
      "13       6/4/2013   6/4/2013 16:00      90.0   Tuesday      6    4  2013   \n",
      "14       6/4/2013   6/4/2013 16:30     120.0   Tuesday      6    4  2013   \n",
      "15       6/4/2013   6/4/2013 17:00      90.0   Tuesday      6    4  2013   \n",
      "16       6/4/2013   6/4/2013 17:30     100.0   Tuesday      6    4  2013   \n",
      "17       6/4/2013   6/4/2013 18:00      90.0   Tuesday      6    4  2013   \n",
      "18       6/4/2013   6/4/2013 18:30     120.0   Tuesday      6    4  2013   \n",
      "19       6/4/2013   6/4/2013 19:00      90.0   Tuesday      6    4  2013   \n",
      "20       6/4/2013   6/4/2013 19:30      90.0   Tuesday      6    4  2013   \n",
      "21       6/4/2013   6/4/2013 20:00     100.0   Tuesday      6    4  2013   \n",
      "22       6/4/2013   6/4/2013 20:00      90.0   Tuesday      6    4  2013   \n",
      "23       6/4/2013   6/4/2013 20:30      60.0   Tuesday      6    4  2013   \n",
      "24       6/4/2013   6/4/2013 21:00      60.0   Tuesday      6    4  2013   \n",
      "25      5/23/2014   5/23/2014 7:12     120.0    Friday      5   23  2014   \n",
      "26      5/23/2014   5/23/2014 7:21      35.0    Friday      5   23  2014   \n",
      "27      5/23/2014   5/23/2014 7:32      90.0    Friday      5   23  2014   \n",
      "28      5/23/2014   5/23/2014 7:35      90.0    Friday      5   23  2014   \n",
      "29      5/23/2014   5/23/2014 7:45      60.0    Friday      5   23  2014   \n",
      "...           ...              ...       ...       ...    ...  ...   ...   \n",
      "243892  3/31/2019  3/31/2019 18:56      90.0    Sunday      3   31  2019   \n",
      "243893  3/31/2019  3/31/2019 19:00      90.0    Sunday      3   31  2019   \n",
      "243894  3/31/2019  3/31/2019 19:07      90.0    Sunday      3   31  2019   \n",
      "243895  3/31/2019  3/31/2019 19:14      90.0    Sunday      3   31  2019   \n",
      "243896  3/31/2019  3/31/2019 19:21      90.0    Sunday      3   31  2019   \n",
      "243897  3/31/2019  3/31/2019 19:27      90.0    Sunday      3   31  2019   \n",
      "243898  3/31/2019  3/31/2019 19:35      90.0    Sunday      3   31  2019   \n",
      "243899  3/31/2019  3/31/2019 19:42      90.0    Sunday      3   31  2019   \n",
      "243900  3/31/2019  3/31/2019 19:49      85.0    Sunday      3   31  2019   \n",
      "243901  3/31/2019  3/31/2019 19:56      85.0    Sunday      3   31  2019   \n",
      "243902  3/31/2019  3/31/2019 20:00      85.0    Sunday      3   31  2019   \n",
      "243903  3/31/2019  3/31/2019 20:07      90.0    Sunday      3   31  2019   \n",
      "243904  3/31/2019  3/31/2019 20:14      90.0    Sunday      3   31  2019   \n",
      "243905  3/31/2019  3/31/2019 20:21      90.0    Sunday      3   31  2019   \n",
      "243906  3/31/2019  3/31/2019 20:27      85.0    Sunday      3   31  2019   \n",
      "243907  3/31/2019  3/31/2019 20:35      85.0    Sunday      3   31  2019   \n",
      "243908  3/31/2019  3/31/2019 20:42      85.0    Sunday      3   31  2019   \n",
      "243909  3/31/2019  3/31/2019 20:49      80.0    Sunday      3   31  2019   \n",
      "243910  3/31/2019  3/31/2019 20:56      80.0    Sunday      3   31  2019   \n",
      "243911  3/31/2019  3/31/2019 21:00      80.0    Sunday      3   31  2019   \n",
      "243912  3/31/2019  3/31/2019 21:07      75.0    Sunday      3   31  2019   \n",
      "243913  3/31/2019  3/31/2019 21:14      30.0    Sunday      3   31  2019   \n",
      "243914  3/31/2019  3/31/2019 21:21      30.0    Sunday      3   31  2019   \n",
      "243915  3/31/2019  3/31/2019 21:27      40.0    Sunday      3   31  2019   \n",
      "243916  3/31/2019  3/31/2019 21:35      40.0    Sunday      3   31  2019   \n",
      "243917  3/31/2019  3/31/2019 21:42      40.0    Sunday      3   31  2019   \n",
      "243918  3/31/2019  3/31/2019 21:47      55.0    Sunday      3   31  2019   \n",
      "243919  3/31/2019  3/31/2019 21:49      55.0    Sunday      3   31  2019   \n",
      "243920  3/31/2019  3/31/2019 21:56      45.0    Sunday      3   31  2019   \n",
      "243921  3/31/2019  3/31/2019 22:00      35.0    Sunday      3   31  2019   \n",
      "\n",
      "        Hour  Minute  \n",
      "0          9       0  \n",
      "1          9      30  \n",
      "2         10       0  \n",
      "3         10      30  \n",
      "4         11       0  \n",
      "5         11      30  \n",
      "6         12       0  \n",
      "7         13       0  \n",
      "8         13      30  \n",
      "9         14       0  \n",
      "10        15       0  \n",
      "11        15      30  \n",
      "12        16       0  \n",
      "13        16       0  \n",
      "14        16      30  \n",
      "15        17       0  \n",
      "16        17      30  \n",
      "17        18       0  \n",
      "18        18      30  \n",
      "19        19       0  \n",
      "20        19      30  \n",
      "21        20       0  \n",
      "22        20       0  \n",
      "23        20      30  \n",
      "24        21       0  \n",
      "25         7      12  \n",
      "26         7      21  \n",
      "27         7      32  \n",
      "28         7      35  \n",
      "29         7      45  \n",
      "...      ...     ...  \n",
      "243892    18      56  \n",
      "243893    19       0  \n",
      "243894    19       7  \n",
      "243895    19      14  \n",
      "243896    19      21  \n",
      "243897    19      27  \n",
      "243898    19      35  \n",
      "243899    19      42  \n",
      "243900    19      49  \n",
      "243901    19      56  \n",
      "243902    20       0  \n",
      "243903    20       7  \n",
      "243904    20      14  \n",
      "243905    20      21  \n",
      "243906    20      27  \n",
      "243907    20      35  \n",
      "243908    20      42  \n",
      "243909    20      49  \n",
      "243910    20      56  \n",
      "243911    21       0  \n",
      "243912    21       7  \n",
      "243913    21      14  \n",
      "243914    21      21  \n",
      "243915    21      27  \n",
      "243916    21      35  \n",
      "243917    21      42  \n",
      "243918    21      47  \n",
      "243919    21      49  \n",
      "243920    21      56  \n",
      "243921    22       0  \n",
      "\n",
      "[227645 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_initial.loc[0]['SPOSTMIN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = df_initial['SPOSTMIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_DOW = LabelEncoder()\n",
    "DoW_feature = label_encoder_DOW.fit_transform(df_initial.DAYOFWEEK.iloc[:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_col = pd.Series(DoW_feature)\n",
    "df_initial['DayOfWeek'] = DoW_feature\n",
    "df_initial = df_initial.drop(columns=[\"DAYOFWEEK\", \"date\", \"datetime\", \"SPOSTMIN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Month  Day  Year  Hour  Minute  DayOfWeek\n",
      "0           6    4  2013     9       0          5\n",
      "1           6    4  2013     9      30          5\n",
      "2           6    4  2013    10       0          5\n",
      "3           6    4  2013    10      30          5\n",
      "4           6    4  2013    11       0          5\n",
      "5           6    4  2013    11      30          5\n",
      "6           6    4  2013    12       0          5\n",
      "7           6    4  2013    13       0          5\n",
      "8           6    4  2013    13      30          5\n",
      "9           6    4  2013    14       0          5\n",
      "10          6    4  2013    15       0          5\n",
      "11          6    4  2013    15      30          5\n",
      "12          6    4  2013    16       0          5\n",
      "13          6    4  2013    16       0          5\n",
      "14          6    4  2013    16      30          5\n",
      "15          6    4  2013    17       0          5\n",
      "16          6    4  2013    17      30          5\n",
      "17          6    4  2013    18       0          5\n",
      "18          6    4  2013    18      30          5\n",
      "19          6    4  2013    19       0          5\n",
      "20          6    4  2013    19      30          5\n",
      "21          6    4  2013    20       0          5\n",
      "22          6    4  2013    20       0          5\n",
      "23          6    4  2013    20      30          5\n",
      "24          6    4  2013    21       0          5\n",
      "25          5   23  2014     7      12          0\n",
      "26          5   23  2014     7      21          0\n",
      "27          5   23  2014     7      32          0\n",
      "28          5   23  2014     7      35          0\n",
      "29          5   23  2014     7      45          0\n",
      "...       ...  ...   ...   ...     ...        ...\n",
      "243892      3   31  2019    18      56          3\n",
      "243893      3   31  2019    19       0          3\n",
      "243894      3   31  2019    19       7          3\n",
      "243895      3   31  2019    19      14          3\n",
      "243896      3   31  2019    19      21          3\n",
      "243897      3   31  2019    19      27          3\n",
      "243898      3   31  2019    19      35          3\n",
      "243899      3   31  2019    19      42          3\n",
      "243900      3   31  2019    19      49          3\n",
      "243901      3   31  2019    19      56          3\n",
      "243902      3   31  2019    20       0          3\n",
      "243903      3   31  2019    20       7          3\n",
      "243904      3   31  2019    20      14          3\n",
      "243905      3   31  2019    20      21          3\n",
      "243906      3   31  2019    20      27          3\n",
      "243907      3   31  2019    20      35          3\n",
      "243908      3   31  2019    20      42          3\n",
      "243909      3   31  2019    20      49          3\n",
      "243910      3   31  2019    20      56          3\n",
      "243911      3   31  2019    21       0          3\n",
      "243912      3   31  2019    21       7          3\n",
      "243913      3   31  2019    21      14          3\n",
      "243914      3   31  2019    21      21          3\n",
      "243915      3   31  2019    21      27          3\n",
      "243916      3   31  2019    21      35          3\n",
      "243917      3   31  2019    21      42          3\n",
      "243918      3   31  2019    21      47          3\n",
      "243919      3   31  2019    21      49          3\n",
      "243920      3   31  2019    21      56          3\n",
      "243921      3   31  2019    22       0          3\n",
      "\n",
      "[227645 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(max(df_initial.loc[:,'Month']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 5\n",
    "t_s = .20\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_initial, df_y, test_size = t_s, random_state = random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [100, 200, 300], #random int btwn 100 and 500 - removed\n",
    "              'learning_rate': stats.uniform(0.01, 0.08), #.01 + loc, range of .01+/-.08\n",
    "              'max_depth': [2, 4, 6, 8], #tree depths to check\n",
    "              'colsample_bytree': stats.uniform(0.3, 0.7) #btwn .1 and 1.0    \n",
    "}\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=random_seed)\n",
    "model = XGBRegressor(tree_method='gpu_hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] colsample_bytree=0.87039834402735, learning_rate=0.036085559562499425, max_depth=8, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.87039834402735, learning_rate=0.036085559562499425, max_depth=8, n_estimators=300, score=0.006386082410054228, total=  16.4s\n",
      "[CV] colsample_bytree=0.87039834402735, learning_rate=0.036085559562499425, max_depth=8, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.87039834402735, learning_rate=0.036085559562499425, max_depth=8, n_estimators=300, score=-47.266328286227505, total=  15.6s\n",
      "[CV] colsample_bytree=0.87039834402735, learning_rate=0.036085559562499425, max_depth=8, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   32.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.87039834402735, learning_rate=0.036085559562499425, max_depth=8, n_estimators=300, score=-4.45785211494758, total=  14.8s\n",
      "[CV] colsample_bytree=0.8027843486747859, learning_rate=0.05947744568872531, max_depth=8, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   47.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8027843486747859, learning_rate=0.05947744568872531, max_depth=8, n_estimators=100, score=0.005993892360712572, total=   5.0s\n",
      "[CV] colsample_bytree=0.8027843486747859, learning_rate=0.05947744568872531, max_depth=8, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   52.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8027843486747859, learning_rate=0.05947744568872531, max_depth=8, n_estimators=100, score=-27.89695723684013, total=   5.0s\n",
      "[CV] colsample_bytree=0.8027843486747859, learning_rate=0.05947744568872531, max_depth=8, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   57.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8027843486747859, learning_rate=0.05947744568872531, max_depth=8, n_estimators=100, score=-0.965691763953161, total=   5.0s\n",
      "[CV] colsample_bytree=0.9596276141282687, learning_rate=0.08580040161762502, max_depth=8, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9596276141282687, learning_rate=0.08580040161762502, max_depth=8, n_estimators=100, score=0.006261661076658043, total=   4.9s\n",
      "[CV] colsample_bytree=0.9596276141282687, learning_rate=0.08580040161762502, max_depth=8, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9596276141282687, learning_rate=0.08580040161762502, max_depth=8, n_estimators=100, score=-38.45960926387023, total=   4.9s\n",
      "[CV] colsample_bytree=0.9596276141282687, learning_rate=0.08580040161762502, max_depth=8, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9596276141282687, learning_rate=0.08580040161762502, max_depth=8, n_estimators=100, score=-1.470753911618281, total=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -9.618832 using {'colsample_bytree': 0.8027843486747859, 'learning_rate': 0.05947744568872531, 'max_depth': 8, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "rand_search = RandomizedSearchCV(model, param_distributions = param_grid, scoring = 'explained_variance', n_iter = 3, verbose = 10, cv=kfold)\n",
    "rand_result = rand_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (rand_result.best_score_, rand_result.best_params_))\n",
    "best_XGB_estimator = rand_result.best_estimator_\n",
    "pickle.dump(best_XGB_estimator, open(\"xgb_dwarves.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.08, max_delta_step=0,\n",
       "       max_depth=7, min_child_weight=1, missing=None, n_estimators=300,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.75)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor(n_estimators=300, learning_rate=0.08, gamma=0, subsample=0.75, colsample_bytree=1, max_depth=7)\n",
    "xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.252192115333184\n"
     ]
    }
   ],
   "source": [
    "predictions = xgb.predict(X_test)\n",
    "print(explained_variance_score(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(xgb, open('xgb_dwarves_nonsearch.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_test.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Month  Day  Year  Hour  Minute  DayOfWeek\n",
      "66977       8   12  2015    18      21          6\n",
      "68450       8   25  2015     9      49          5\n",
      "21056      11    4  2014     9      32          5\n",
      "187242      3   14  2018    17      21          6\n",
      "155766      8    6  2017    19      15          3\n",
      "240577      3    9  2019    17      49          2\n",
      "187936      3   19  2018    10      14          1\n",
      "175135     12   17  2017     9      35          3\n",
      "212631      9    5  2018    10      49          6\n",
      "196929      5   24  2018    19       0          4\n",
      "195993      5   17  2018    21      56          4\n",
      "82778      12    8  2015    20       7          5\n",
      "50334       5    6  2015     9      30          6\n",
      "79642      11   16  2015    16      56          1\n",
      "38044       2   21  2015    13      45          2\n",
      "233616      1   18  2019    15      56          0\n",
      "176558     12   25  2017    21      49          1\n",
      "137223      3   10  2017    11      56          0\n",
      "168562     11    4  2017    15      58          2\n",
      "215093      9   21  2018    16       0          0\n",
      "115354      9    2  2016    11       0          0\n",
      "122545     11    3  2016    11      35          4\n",
      "129291     12   26  2016    19      14          1\n",
      "47877       4   21  2015    20      15          5\n",
      "190908      4    7  2018    15      56          2\n",
      "142918      4   25  2017    15      21          5\n",
      "78307      11    6  2015    21      27          0\n",
      "239482      3    1  2019    21       0          0\n",
      "227698     12   11  2018    18      49          5\n",
      "142521      4   21  2017    20       0          0\n",
      "...       ...  ...   ...   ...     ...        ...\n",
      "170186     11   15  2017    10      42          6\n",
      "116214      9    9  2016    15       7          0\n",
      "124487     11   19  2016    15      42          2\n",
      "82568      12    7  2015    10      49          1\n",
      "101428      5   12  2016    19      16          4\n",
      "66456       8    8  2015     0      35          2\n",
      "86973       1    7  2016    20       7          4\n",
      "198657      6    5  2018    13      21          5\n",
      "1796        6    7  2014    16      21          2\n",
      "190646      4    5  2018    21      49          4\n",
      "98568       4   13  2016    18      56          6\n",
      "242960      3   25  2019    15       7          1\n",
      "239328      2   28  2019    20      49          4\n",
      "184454      2   22  2018    10      21          4\n",
      "114651      8   27  2016     9      35          2\n",
      "104204      6    4  2016    10      57          2\n",
      "220033     10   23  2018    13      27          5\n",
      "127205     12   10  2016    14      42          2\n",
      "111826      8    5  2016     9      27          0\n",
      "85997      12   31  2015    12      42          4\n",
      "4859        7    7  2014     9       4          1\n",
      "225061     11   25  2018    14      49          3\n",
      "191513      4   11  2018    21      25          6\n",
      "152155      7   10  2017    21      21          1\n",
      "241801      3   17  2019    19      49          3\n",
      "92953       2   29  2016    20      35          1\n",
      "4407        7    3  2014    12      58          4\n",
      "128011     12   17  2016     9      35          2\n",
      "115713      9    4  2016    23      14          3\n",
      "72203       9   22  2015    16       2          5\n",
      "\n",
      "[45529 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 4, 2013, 9, 0, 5]]\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open('xgb_dwarves.pkl','rb'))\n",
    "month = 6\n",
    "day = 4\n",
    "year = 2013\n",
    "hour = 9\n",
    "minute = 0\n",
    "dayofweek = 5\n",
    "data = [[month, day, year, hour, minute, dayofweek]]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Month  Day  Year  Hour  Minute  DayOfWeek\n",
      "0      6    4  2013     9       0          5\n"
     ]
    }
   ],
   "source": [
    "input_df = pd.DataFrame(data, columns =['Month','Day','Year','Hour','Minute','DayOfWeek'])\n",
    "print(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41.452232]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] colsample_bytree=0.577976915017408, learning_rate=0.06002926970353843, max_depth=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.577976915017408, learning_rate=0.06002926970353843, max_depth=2, n_estimators=200, score=0.4447262116945443, total=   0.2s\n",
      "[CV] colsample_bytree=0.577976915017408, learning_rate=0.06002926970353843, max_depth=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.577976915017408, learning_rate=0.06002926970353843, max_depth=2, n_estimators=200, score=0.4567281211554609, total=   0.2s\n",
      "[CV] colsample_bytree=0.577976915017408, learning_rate=0.06002926970353843, max_depth=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.577976915017408, learning_rate=0.06002926970353843, max_depth=2, n_estimators=200, score=0.4220322500180581, total=   0.2s\n",
      "[CV] colsample_bytree=0.5164940677309758, learning_rate=0.0423351957354838, max_depth=6, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.5164940677309758, learning_rate=0.0423351957354838, max_depth=6, n_estimators=200, score=0.6860681757844085, total=   2.1s\n",
      "[CV] colsample_bytree=0.5164940677309758, learning_rate=0.0423351957354838, max_depth=6, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    3.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.5164940677309758, learning_rate=0.0423351957354838, max_depth=6, n_estimators=200, score=0.6844072313321747, total=   2.1s\n",
      "[CV] colsample_bytree=0.5164940677309758, learning_rate=0.0423351957354838, max_depth=6, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.5164940677309758, learning_rate=0.0423351957354838, max_depth=6, n_estimators=200, score=0.6927774349548144, total=   2.1s\n",
      "[CV] colsample_bytree=0.8126016842908925, learning_rate=0.011670201080323723, max_depth=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    7.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8126016842908925, learning_rate=0.011670201080323723, max_depth=2, n_estimators=200, score=0.30511549560772655, total=   0.2s\n",
      "[CV] colsample_bytree=0.8126016842908925, learning_rate=0.011670201080323723, max_depth=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    7.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8126016842908925, learning_rate=0.011670201080323723, max_depth=2, n_estimators=200, score=0.31701837859390325, total=   0.2s\n",
      "[CV] colsample_bytree=0.8126016842908925, learning_rate=0.011670201080323723, max_depth=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    8.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8126016842908925, learning_rate=0.011670201080323723, max_depth=2, n_estimators=200, score=0.29188853694420935, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    8.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    8.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.687751 using {'colsample_bytree': 0.5164940677309758, 'learning_rate': 0.0423351957354838, 'max_depth': 6, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "df_initial = pd.read_csv('alien_saucers.csv')\n",
    "for index, row in df_initial.iterrows():\n",
    "    if math.isnan(row['SPOSTMIN']):\n",
    "        df_initial.loc[index,'SPOSTMIN'] = df_initial.loc[index, 'SACTMIN']\n",
    "#     print(row['SPOSTMIN'], row['SACTMIN'])\n",
    "df_initial = df_initial.drop(columns=\"SACTMIN\")\n",
    "df_initial = df_initial[df_initial['SPOSTMIN'] != -999]\n",
    "df_initial['Month'] = df_initial.date.str.split('/').str[0]\n",
    "df_initial['Day'] = df_initial.date.str.split('/').str[1]\n",
    "df_initial['Year'] = df_initial.date.str.rsplit('/', 1).str[1]\n",
    "df_initial['Time_char'] = df_initial.datetime.str.split(' ').str[1]\n",
    "df_initial['Hour'] = df_initial['Time_char'].str.split(':').str[0]\n",
    "df_initial['Minute'] = df_initial['Time_char'].str.split(':').str[1]\n",
    "df_initial = df_initial.drop(columns=\"Time_char\")\n",
    "df_initial['Month'] = (df_initial['Month']).astype(int)\n",
    "df_initial['Day'] = (df_initial['Day']).astype(int)\n",
    "df_initial['Year'] = (df_initial['Year']).astype(int)\n",
    "df_initial['Hour'] = (df_initial['Hour']).astype(int)\n",
    "df_initial['Minute'] = (df_initial['Minute']).astype(int)\n",
    "df_y = df_initial['SPOSTMIN']\n",
    "label_encoder_DOW = LabelEncoder()\n",
    "DoW_feature = label_encoder_DOW.fit_transform(df_initial.DAYOFWEEK.iloc[:].values)\n",
    "# new_col = pd.Series(DoW_feature)\n",
    "df_initial['DayOfWeek'] = DoW_feature\n",
    "df_initial = df_initial.drop(columns=[\"DAYOFWEEK\", \"date\", \"datetime\", \"SPOSTMIN\"])\n",
    "random_seed = 5\n",
    "t_s = .20\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_initial, df_y, test_size = t_s, random_state = random_seed)\n",
    "param_grid = {'n_estimators': [100, 200, 300], #random int btwn 100 and 500 - removed\n",
    "              'learning_rate': stats.uniform(0.01, 0.08), #.01 + loc, range of .01+/-.08\n",
    "              'max_depth': [2, 4, 6, 8], #tree depths to check\n",
    "              'colsample_bytree': stats.uniform(0.3, 0.7) #btwn .1 and 1.0    \n",
    "}\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=random_seed)\n",
    "model = XGBRegressor(tree_method='gpu_hist')\n",
    "rand_search = RandomizedSearchCV(model, param_distributions = param_grid, scoring = 'explained_variance', n_iter = 3, verbose = 10, cv=kfold)\n",
    "rand_result = rand_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (rand_result.best_score_, rand_result.best_params_))\n",
    "best_XGB_estimator = rand_result.best_estimator_\n",
    "pickle.dump(best_XGB_estimator, open(\"xgb_alien_saucers.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] colsample_bytree=0.3788152731681116, learning_rate=0.03763450269760868, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.3788152731681116, learning_rate=0.03763450269760868, max_depth=4, n_estimators=100, score=0.3305039087984535, total=   0.5s\n",
      "[CV] colsample_bytree=0.3788152731681116, learning_rate=0.03763450269760868, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.3788152731681116, learning_rate=0.03763450269760868, max_depth=4, n_estimators=100, score=0.32828419390423036, total=   0.5s\n",
      "[CV] colsample_bytree=0.3788152731681116, learning_rate=0.03763450269760868, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.3788152731681116, learning_rate=0.03763450269760868, max_depth=4, n_estimators=100, score=0.33014473016703194, total=   0.5s\n",
      "[CV] colsample_bytree=0.32837068043255735, learning_rate=0.051036144348603554, max_depth=8, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.32837068043255735, learning_rate=0.051036144348603554, max_depth=8, n_estimators=200, score=0.3401325824749507, total=   1.4s\n",
      "[CV] colsample_bytree=0.32837068043255735, learning_rate=0.051036144348603554, max_depth=8, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    3.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.32837068043255735, learning_rate=0.051036144348603554, max_depth=8, n_estimators=200, score=0.33824532697476795, total=   1.3s\n",
      "[CV] colsample_bytree=0.32837068043255735, learning_rate=0.051036144348603554, max_depth=8, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    4.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.32837068043255735, learning_rate=0.051036144348603554, max_depth=8, n_estimators=200, score=0.3422653129298958, total=   1.4s\n",
      "[CV] colsample_bytree=0.6859201280124755, learning_rate=0.04250813727131032, max_depth=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    6.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.6859201280124755, learning_rate=0.04250813727131032, max_depth=2, n_estimators=200, score=0.3756878805030033, total=   0.5s\n",
      "[CV] colsample_bytree=0.6859201280124755, learning_rate=0.04250813727131032, max_depth=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    6.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.6859201280124755, learning_rate=0.04250813727131032, max_depth=2, n_estimators=200, score=0.37636754996530175, total=   0.5s\n",
      "[CV] colsample_bytree=0.6859201280124755, learning_rate=0.04250813727131032, max_depth=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    7.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.6859201280124755, learning_rate=0.04250813727131032, max_depth=2, n_estimators=200, score=0.37522729181482106, total=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    8.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    8.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.375761 using {'colsample_bytree': 0.6859201280124755, 'learning_rate': 0.04250813727131032, 'max_depth': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "df_initial = pd.read_csv('dinosaur.csv')\n",
    "for index, row in df_initial.iterrows():\n",
    "    if math.isnan(row['SPOSTMIN']):\n",
    "        df_initial.loc[index,'SPOSTMIN'] = df_initial.loc[index, 'SACTMIN']\n",
    "#     print(row['SPOSTMIN'], row['SACTMIN'])\n",
    "df_initial = df_initial.drop(columns=\"SACTMIN\")\n",
    "df_initial = df_initial[df_initial['SPOSTMIN'] != -999]\n",
    "df_initial['Month'] = df_initial.date.str.split('/').str[0]\n",
    "df_initial['Day'] = df_initial.date.str.split('/').str[1]\n",
    "df_initial['Year'] = df_initial.date.str.rsplit('/', 1).str[1]\n",
    "df_initial['Time_char'] = df_initial.datetime.str.split(' ').str[1]\n",
    "df_initial['Hour'] = df_initial['Time_char'].str.split(':').str[0]\n",
    "df_initial['Minute'] = df_initial['Time_char'].str.split(':').str[1]\n",
    "df_initial = df_initial.drop(columns=\"Time_char\")\n",
    "df_initial['Month'] = (df_initial['Month']).astype(int)\n",
    "df_initial['Day'] = (df_initial['Day']).astype(int)\n",
    "df_initial['Year'] = (df_initial['Year']).astype(int)\n",
    "df_initial['Hour'] = (df_initial['Hour']).astype(int)\n",
    "df_initial['Minute'] = (df_initial['Minute']).astype(int)\n",
    "df_y = df_initial['SPOSTMIN']\n",
    "label_encoder_DOW = LabelEncoder()\n",
    "DoW_feature = label_encoder_DOW.fit_transform(df_initial.DAYOFWEEK.iloc[:].values)\n",
    "# new_col = pd.Series(DoW_feature)\n",
    "df_initial['DayOfWeek'] = DoW_feature\n",
    "df_initial = df_initial.drop(columns=[\"DAYOFWEEK\", \"date\", \"datetime\", \"SPOSTMIN\"])\n",
    "random_seed = 5\n",
    "t_s = .20\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_initial, df_y, test_size = t_s, random_state = random_seed)\n",
    "param_grid = {'n_estimators': [100, 200, 300], #random int btwn 100 and 500 - removed\n",
    "              'learning_rate': stats.uniform(0.01, 0.08), #.01 + loc, range of .01+/-.08\n",
    "              'max_depth': [2, 4, 6, 8], #tree depths to check\n",
    "              'colsample_bytree': stats.uniform(0.3, 0.7) #btwn .1 and 1.0    \n",
    "}\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=random_seed)\n",
    "model = XGBRegressor(tree_method='gpu_hist')\n",
    "rand_search = RandomizedSearchCV(model, param_distributions = param_grid, scoring = 'explained_variance', n_iter = 3, verbose = 10, cv=kfold)\n",
    "rand_result = rand_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (rand_result.best_score_, rand_result.best_params_))\n",
    "best_XGB_estimator = rand_result.best_estimator_\n",
    "pickle.dump(best_XGB_estimator, open(\"xgb_dinosaur.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] colsample_bytree=0.5520118345812709, learning_rate=0.04062364873027281, max_depth=2, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.5520118345812709, learning_rate=0.04062364873027281, max_depth=2, n_estimators=300, score=0.4722528198216195, total=   0.8s\n",
      "[CV] colsample_bytree=0.5520118345812709, learning_rate=0.04062364873027281, max_depth=2, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.5520118345812709, learning_rate=0.04062364873027281, max_depth=2, n_estimators=300, score=0.47288870918773196, total=   0.8s\n",
      "[CV] colsample_bytree=0.5520118345812709, learning_rate=0.04062364873027281, max_depth=2, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.5520118345812709, learning_rate=0.04062364873027281, max_depth=2, n_estimators=300, score=0.468079306258227, total=   0.8s\n",
      "[CV] colsample_bytree=0.385248419026763, learning_rate=0.0117244229397226, max_depth=6, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.385248419026763, learning_rate=0.0117244229397226, max_depth=6, n_estimators=100, score=0.24573216204728143, total=   1.3s\n",
      "[CV] colsample_bytree=0.385248419026763, learning_rate=0.0117244229397226, max_depth=6, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.385248419026763, learning_rate=0.0117244229397226, max_depth=6, n_estimators=100, score=0.24689745232382665, total=   1.3s\n",
      "[CV] colsample_bytree=0.385248419026763, learning_rate=0.0117244229397226, max_depth=6, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.385248419026763, learning_rate=0.0117244229397226, max_depth=6, n_estimators=100, score=0.2463104096618527, total=   1.3s\n",
      "[CV] colsample_bytree=0.7168642025772023, learning_rate=0.0762026436042897, max_depth=8, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    6.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7168642025772023, learning_rate=0.0762026436042897, max_depth=8, n_estimators=100, score=0.725835318362474, total=   5.0s\n",
      "[CV] colsample_bytree=0.7168642025772023, learning_rate=0.0762026436042897, max_depth=8, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   12.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7168642025772023, learning_rate=0.0762026436042897, max_depth=8, n_estimators=100, score=0.7294919425571937, total=   5.1s\n",
      "[CV] colsample_bytree=0.7168642025772023, learning_rate=0.0762026436042897, max_depth=8, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   17.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7168642025772023, learning_rate=0.0762026436042897, max_depth=8, n_estimators=100, score=0.7236383494320533, total=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   22.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   22.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.726322 using {'colsample_bytree': 0.7168642025772023, 'learning_rate': 0.0762026436042897, 'max_depth': 8, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "df_initial = pd.read_csv('expedition_everest.csv')\n",
    "for index, row in df_initial.iterrows():\n",
    "    if math.isnan(row['SPOSTMIN']):\n",
    "        df_initial.loc[index,'SPOSTMIN'] = df_initial.loc[index, 'SACTMIN']\n",
    "#     print(row['SPOSTMIN'], row['SACTMIN'])\n",
    "df_initial = df_initial.drop(columns=\"SACTMIN\")\n",
    "df_initial = df_initial[df_initial['SPOSTMIN'] != -999]\n",
    "df_initial['Month'] = df_initial.date.str.split('/').str[0]\n",
    "df_initial['Day'] = df_initial.date.str.split('/').str[1]\n",
    "df_initial['Year'] = df_initial.date.str.rsplit('/', 1).str[1]\n",
    "df_initial['Time_char'] = df_initial.datetime.str.split(' ').str[1]\n",
    "df_initial['Hour'] = df_initial['Time_char'].str.split(':').str[0]\n",
    "df_initial['Minute'] = df_initial['Time_char'].str.split(':').str[1]\n",
    "df_initial = df_initial.drop(columns=\"Time_char\")\n",
    "df_initial['Month'] = (df_initial['Month']).astype(int)\n",
    "df_initial['Day'] = (df_initial['Day']).astype(int)\n",
    "df_initial['Year'] = (df_initial['Year']).astype(int)\n",
    "df_initial['Hour'] = (df_initial['Hour']).astype(int)\n",
    "df_initial['Minute'] = (df_initial['Minute']).astype(int)\n",
    "df_y = df_initial['SPOSTMIN']\n",
    "label_encoder_DOW = LabelEncoder()\n",
    "DoW_feature = label_encoder_DOW.fit_transform(df_initial.DAYOFWEEK.iloc[:].values)\n",
    "# new_col = pd.Series(DoW_feature)\n",
    "df_initial['DayOfWeek'] = DoW_feature\n",
    "df_initial = df_initial.drop(columns=[\"DAYOFWEEK\", \"date\", \"datetime\", \"SPOSTMIN\"])\n",
    "random_seed = 5\n",
    "t_s = .20\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_initial, df_y, test_size = t_s, random_state = random_seed)\n",
    "param_grid = {'n_estimators': [100, 200, 300], #random int btwn 100 and 500 - removed\n",
    "              'learning_rate': stats.uniform(0.01, 0.08), #.01 + loc, range of .01+/-.08\n",
    "              'max_depth': [2, 4, 6, 8], #tree depths to check\n",
    "              'colsample_bytree': stats.uniform(0.3, 0.7) #btwn .1 and 1.0    \n",
    "}\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=random_seed)\n",
    "model = XGBRegressor(tree_method='gpu_hist')\n",
    "rand_search = RandomizedSearchCV(model, param_distributions = param_grid, scoring = 'explained_variance', n_iter = 3, verbose = 10, cv=kfold)\n",
    "rand_result = rand_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (rand_result.best_score_, rand_result.best_params_))\n",
    "best_XGB_estimator = rand_result.best_estimator_\n",
    "pickle.dump(best_XGB_estimator, open(\"xgb_expedition_everest.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] colsample_bytree=0.3421465446336176, learning_rate=0.022001785127876525, max_depth=6, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.3421465446336176, learning_rate=0.022001785127876525, max_depth=6, n_estimators=100, score=0.003935369031655256, total=   0.9s\n",
      "[CV] colsample_bytree=0.3421465446336176, learning_rate=0.022001785127876525, max_depth=6, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.3421465446336176, learning_rate=0.022001785127876525, max_depth=6, n_estimators=100, score=-0.015520592779881826, total=   0.9s\n",
      "[CV] colsample_bytree=0.3421465446336176, learning_rate=0.022001785127876525, max_depth=6, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.3421465446336176, learning_rate=0.022001785127876525, max_depth=6, n_estimators=100, score=0.008135198269304311, total=   0.9s\n",
      "[CV] colsample_bytree=0.34640610354852347, learning_rate=0.0647676420993673, max_depth=6, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.34640610354852347, learning_rate=0.0647676420993673, max_depth=6, n_estimators=300, score=-2.646395910608601, total=   3.1s\n",
      "[CV] colsample_bytree=0.34640610354852347, learning_rate=0.0647676420993673, max_depth=6, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    6.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.34640610354852347, learning_rate=0.0647676420993673, max_depth=6, n_estimators=300, score=-2.9884744203433864, total=   3.0s\n",
      "[CV] colsample_bytree=0.34640610354852347, learning_rate=0.0647676420993673, max_depth=6, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.34640610354852347, learning_rate=0.0647676420993673, max_depth=6, n_estimators=300, score=0.014723403688300496, total=   3.0s\n",
      "[CV] colsample_bytree=0.7345277052079023, learning_rate=0.027467861334061663, max_depth=8, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   12.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7345277052079023, learning_rate=0.027467861334061663, max_depth=8, n_estimators=100, score=-0.6614832822603196, total=   4.1s\n",
      "[CV] colsample_bytree=0.7345277052079023, learning_rate=0.027467861334061663, max_depth=8, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   16.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7345277052079023, learning_rate=0.027467861334061663, max_depth=8, n_estimators=100, score=-0.11011598028759129, total=   4.1s\n",
      "[CV] colsample_bytree=0.7345277052079023, learning_rate=0.027467861334061663, max_depth=8, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   20.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7345277052079023, learning_rate=0.027467861334061663, max_depth=8, n_estimators=100, score=0.014981626658876812, total=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   25.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   25.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.001150 using {'colsample_bytree': 0.3421465446336176, 'learning_rate': 0.022001785127876525, 'max_depth': 6, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "df_initial = pd.read_csv('flight_of_passage.csv')\n",
    "for index, row in df_initial.iterrows():\n",
    "    if math.isnan(row['SPOSTMIN']):\n",
    "        df_initial.loc[index,'SPOSTMIN'] = df_initial.loc[index, 'SACTMIN']\n",
    "#     print(row['SPOSTMIN'], row['SACTMIN'])\n",
    "df_initial = df_initial.drop(columns=\"SACTMIN\")\n",
    "df_initial = df_initial[df_initial['SPOSTMIN'] != -999]\n",
    "df_initial['Month'] = df_initial.date.str.split('/').str[0]\n",
    "df_initial['Day'] = df_initial.date.str.split('/').str[1]\n",
    "df_initial['Year'] = df_initial.date.str.rsplit('/', 1).str[1]\n",
    "df_initial['Time_char'] = df_initial.datetime.str.split(' ').str[1]\n",
    "df_initial['Hour'] = df_initial['Time_char'].str.split(':').str[0]\n",
    "df_initial['Minute'] = df_initial['Time_char'].str.split(':').str[1]\n",
    "df_initial = df_initial.drop(columns=\"Time_char\")\n",
    "df_initial['Month'] = (df_initial['Month']).astype(int)\n",
    "df_initial['Day'] = (df_initial['Day']).astype(int)\n",
    "df_initial['Year'] = (df_initial['Year']).astype(int)\n",
    "df_initial['Hour'] = (df_initial['Hour']).astype(int)\n",
    "df_initial['Minute'] = (df_initial['Minute']).astype(int)\n",
    "df_y = df_initial['SPOSTMIN']\n",
    "label_encoder_DOW = LabelEncoder()\n",
    "DoW_feature = label_encoder_DOW.fit_transform(df_initial.DAYOFWEEK.iloc[:].values)\n",
    "# new_col = pd.Series(DoW_feature)\n",
    "df_initial['DayOfWeek'] = DoW_feature\n",
    "df_initial = df_initial.drop(columns=[\"DAYOFWEEK\", \"date\", \"datetime\", \"SPOSTMIN\"])\n",
    "random_seed = 5\n",
    "t_s = .20\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_initial, df_y, test_size = t_s, random_state = random_seed)\n",
    "param_grid = {'n_estimators': [100, 200, 300], #random int btwn 100 and 500 - removed\n",
    "              'learning_rate': stats.uniform(0.01, 0.08), #.01 + loc, range of .01+/-.08\n",
    "              'max_depth': [2, 4, 6, 8], #tree depths to check\n",
    "              'colsample_bytree': stats.uniform(0.3, 0.7) #btwn .1 and 1.0    \n",
    "}\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=random_seed)\n",
    "model = XGBRegressor(tree_method='gpu_hist')\n",
    "rand_search = RandomizedSearchCV(model, param_distributions = param_grid, scoring = 'explained_variance', n_iter = 3, verbose = 10, cv=kfold)\n",
    "rand_result = rand_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (rand_result.best_score_, rand_result.best_params_))\n",
    "best_XGB_estimator = rand_result.best_estimator_\n",
    "pickle.dump(best_XGB_estimator, open(\"xgb_flight_of_passage.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] colsample_bytree=0.5260751836091215, learning_rate=0.08035609113697822, max_depth=8, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.5260751836091215, learning_rate=0.08035609113697822, max_depth=8, n_estimators=200, score=0.6652307626218938, total=   8.7s\n",
      "[CV] colsample_bytree=0.5260751836091215, learning_rate=0.08035609113697822, max_depth=8, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.5260751836091215, learning_rate=0.08035609113697822, max_depth=8, n_estimators=200, score=0.6631760236850532, total=   8.6s\n",
      "[CV] colsample_bytree=0.5260751836091215, learning_rate=0.08035609113697822, max_depth=8, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   17.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.5260751836091215, learning_rate=0.08035609113697822, max_depth=8, n_estimators=200, score=0.667921820631203, total=   8.9s\n",
      "[CV] colsample_bytree=0.941942775789034, learning_rate=0.018879294016387584, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   26.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.941942775789034, learning_rate=0.018879294016387584, max_depth=4, n_estimators=100, score=0.3646020090173371, total=   0.5s\n",
      "[CV] colsample_bytree=0.941942775789034, learning_rate=0.018879294016387584, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   27.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.941942775789034, learning_rate=0.018879294016387584, max_depth=4, n_estimators=100, score=0.36398839774728264, total=   0.5s\n",
      "[CV] colsample_bytree=0.941942775789034, learning_rate=0.018879294016387584, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   27.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.941942775789034, learning_rate=0.018879294016387584, max_depth=4, n_estimators=100, score=0.367775136085541, total=   0.5s\n",
      "[CV] colsample_bytree=0.6513094517022668, learning_rate=0.04047125455705542, max_depth=6, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   28.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.6513094517022668, learning_rate=0.04047125455705542, max_depth=6, n_estimators=100, score=0.4890402482408641, total=   1.4s\n",
      "[CV] colsample_bytree=0.6513094517022668, learning_rate=0.04047125455705542, max_depth=6, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   30.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.6513094517022668, learning_rate=0.04047125455705542, max_depth=6, n_estimators=100, score=0.4865454462123918, total=   1.4s\n",
      "[CV] colsample_bytree=0.6513094517022668, learning_rate=0.04047125455705542, max_depth=6, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   31.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.6513094517022668, learning_rate=0.04047125455705542, max_depth=6, n_estimators=100, score=0.49248089001554074, total=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   33.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   33.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.665443 using {'colsample_bytree': 0.5260751836091215, 'learning_rate': 0.08035609113697822, 'max_depth': 8, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "df_initial = pd.read_csv('kilimanjaro_safaris.csv')\n",
    "for index, row in df_initial.iterrows():\n",
    "    if math.isnan(row['SPOSTMIN']):\n",
    "        df_initial.loc[index,'SPOSTMIN'] = df_initial.loc[index, 'SACTMIN']\n",
    "#     print(row['SPOSTMIN'], row['SACTMIN'])\n",
    "df_initial = df_initial.drop(columns=\"SACTMIN\")\n",
    "df_initial = df_initial[df_initial['SPOSTMIN'] != -999]\n",
    "df_initial['Month'] = df_initial.date.str.split('/').str[0]\n",
    "df_initial['Day'] = df_initial.date.str.split('/').str[1]\n",
    "df_initial['Year'] = df_initial.date.str.rsplit('/', 1).str[1]\n",
    "df_initial['Time_char'] = df_initial.datetime.str.split(' ').str[1]\n",
    "df_initial['Hour'] = df_initial['Time_char'].str.split(':').str[0]\n",
    "df_initial['Minute'] = df_initial['Time_char'].str.split(':').str[1]\n",
    "df_initial = df_initial.drop(columns=\"Time_char\")\n",
    "df_initial['Month'] = (df_initial['Month']).astype(int)\n",
    "df_initial['Day'] = (df_initial['Day']).astype(int)\n",
    "df_initial['Year'] = (df_initial['Year']).astype(int)\n",
    "df_initial['Hour'] = (df_initial['Hour']).astype(int)\n",
    "df_initial['Minute'] = (df_initial['Minute']).astype(int)\n",
    "df_y = df_initial['SPOSTMIN']\n",
    "label_encoder_DOW = LabelEncoder()\n",
    "DoW_feature = label_encoder_DOW.fit_transform(df_initial.DAYOFWEEK.iloc[:].values)\n",
    "# new_col = pd.Series(DoW_feature)\n",
    "df_initial['DayOfWeek'] = DoW_feature\n",
    "df_initial = df_initial.drop(columns=[\"DAYOFWEEK\", \"date\", \"datetime\", \"SPOSTMIN\"])\n",
    "random_seed = 5\n",
    "t_s = .20\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_initial, df_y, test_size = t_s, random_state = random_seed)\n",
    "param_grid = {'n_estimators': [100, 200, 300], #random int btwn 100 and 500 - removed\n",
    "              'learning_rate': stats.uniform(0.01, 0.08), #.01 + loc, range of .01+/-.08\n",
    "              'max_depth': [2, 4, 6, 8], #tree depths to check\n",
    "              'colsample_bytree': stats.uniform(0.3, 0.7) #btwn .1 and 1.0    \n",
    "}\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=random_seed)\n",
    "model = XGBRegressor(tree_method='gpu_hist')\n",
    "rand_search = RandomizedSearchCV(model, param_distributions = param_grid, scoring = 'explained_variance', n_iter = 3, verbose = 10, cv=kfold)\n",
    "rand_result = rand_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (rand_result.best_score_, rand_result.best_params_))\n",
    "best_XGB_estimator = rand_result.best_estimator_\n",
    "pickle.dump(best_XGB_estimator, open(\"xgb_kilimanjaro_safaris.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] colsample_bytree=0.7107008216022356, learning_rate=0.08437304676552695, max_depth=2, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7107008216022356, learning_rate=0.08437304676552695, max_depth=2, n_estimators=300, score=0.5923771663955524, total=   0.5s\n",
      "[CV] colsample_bytree=0.7107008216022356, learning_rate=0.08437304676552695, max_depth=2, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7107008216022356, learning_rate=0.08437304676552695, max_depth=2, n_estimators=300, score=0.5900590214070527, total=   0.5s\n",
      "[CV] colsample_bytree=0.7107008216022356, learning_rate=0.08437304676552695, max_depth=2, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7107008216022356, learning_rate=0.08437304676552695, max_depth=2, n_estimators=300, score=0.5884690539923785, total=   0.4s\n",
      "[CV] colsample_bytree=0.9008114290623426, learning_rate=0.05565181104802352, max_depth=6, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9008114290623426, learning_rate=0.05565181104802352, max_depth=6, n_estimators=100, score=0.6916038492156933, total=   1.3s\n",
      "[CV] colsample_bytree=0.9008114290623426, learning_rate=0.05565181104802352, max_depth=6, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    3.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9008114290623426, learning_rate=0.05565181104802352, max_depth=6, n_estimators=100, score=0.6856765943094658, total=   1.3s\n",
      "[CV] colsample_bytree=0.9008114290623426, learning_rate=0.05565181104802352, max_depth=6, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    4.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9008114290623426, learning_rate=0.05565181104802352, max_depth=6, n_estimators=100, score=0.6859732990840257, total=   1.3s\n",
      "[CV] colsample_bytree=0.39253976183476985, learning_rate=0.05686053902869172, max_depth=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    5.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.39253976183476985, learning_rate=0.05686053902869172, max_depth=2, n_estimators=200, score=0.5160457538203663, total=   0.3s\n",
      "[CV] colsample_bytree=0.39253976183476985, learning_rate=0.05686053902869172, max_depth=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    6.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.39253976183476985, learning_rate=0.05686053902869172, max_depth=2, n_estimators=200, score=0.5141764366877982, total=   0.3s\n",
      "[CV] colsample_bytree=0.39253976183476985, learning_rate=0.05686053902869172, max_depth=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    6.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.39253976183476985, learning_rate=0.05686053902869172, max_depth=2, n_estimators=200, score=0.508146430254097, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    7.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    7.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.687751 using {'colsample_bytree': 0.9008114290623426, 'learning_rate': 0.05565181104802352, 'max_depth': 6, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "df_initial = pd.read_csv('navi_river.csv')\n",
    "for index, row in df_initial.iterrows():\n",
    "    if math.isnan(row['SPOSTMIN']):\n",
    "        df_initial.loc[index,'SPOSTMIN'] = df_initial.loc[index, 'SACTMIN']\n",
    "#     print(row['SPOSTMIN'], row['SACTMIN'])\n",
    "df_initial = df_initial.drop(columns=\"SACTMIN\")\n",
    "df_initial = df_initial[df_initial['SPOSTMIN'] != -999]\n",
    "df_initial['Month'] = df_initial.date.str.split('/').str[0]\n",
    "df_initial['Day'] = df_initial.date.str.split('/').str[1]\n",
    "df_initial['Year'] = df_initial.date.str.rsplit('/', 1).str[1]\n",
    "df_initial['Time_char'] = df_initial.datetime.str.split(' ').str[1]\n",
    "df_initial['Hour'] = df_initial['Time_char'].str.split(':').str[0]\n",
    "df_initial['Minute'] = df_initial['Time_char'].str.split(':').str[1]\n",
    "df_initial = df_initial.drop(columns=\"Time_char\")\n",
    "df_initial['Month'] = (df_initial['Month']).astype(int)\n",
    "df_initial['Day'] = (df_initial['Day']).astype(int)\n",
    "df_initial['Year'] = (df_initial['Year']).astype(int)\n",
    "df_initial['Hour'] = (df_initial['Hour']).astype(int)\n",
    "df_initial['Minute'] = (df_initial['Minute']).astype(int)\n",
    "df_y = df_initial['SPOSTMIN']\n",
    "label_encoder_DOW = LabelEncoder()\n",
    "DoW_feature = label_encoder_DOW.fit_transform(df_initial.DAYOFWEEK.iloc[:].values)\n",
    "# new_col = pd.Series(DoW_feature)\n",
    "df_initial['DayOfWeek'] = DoW_feature\n",
    "df_initial = df_initial.drop(columns=[\"DAYOFWEEK\", \"date\", \"datetime\", \"SPOSTMIN\"])\n",
    "random_seed = 5\n",
    "t_s = .20\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_initial, df_y, test_size = t_s, random_state = random_seed)\n",
    "param_grid = {'n_estimators': [100, 200, 300], #random int btwn 100 and 500 - removed\n",
    "              'learning_rate': stats.uniform(0.01, 0.08), #.01 + loc, range of .01+/-.08\n",
    "              'max_depth': [2, 4, 6, 8], #tree depths to check\n",
    "              'colsample_bytree': stats.uniform(0.3, 0.7) #btwn .1 and 1.0    \n",
    "}\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=random_seed)\n",
    "model = XGBRegressor(tree_method='gpu_hist')\n",
    "rand_search = RandomizedSearchCV(model, param_distributions = param_grid, scoring = 'explained_variance', n_iter = 3, verbose = 10, cv=kfold)\n",
    "rand_result = rand_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (rand_result.best_score_, rand_result.best_params_))\n",
    "best_XGB_estimator = rand_result.best_estimator_\n",
    "pickle.dump(best_XGB_estimator, open(\"xgb_navi_river.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] colsample_bytree=0.9538436675685811, learning_rate=0.05505176812345752, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9538436675685811, learning_rate=0.05505176812345752, max_depth=4, n_estimators=100, score=0.497392743039882, total=   0.7s\n",
      "[CV] colsample_bytree=0.9538436675685811, learning_rate=0.05505176812345752, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9538436675685811, learning_rate=0.05505176812345752, max_depth=4, n_estimators=100, score=0.5528348675411966, total=   0.6s\n",
      "[CV] colsample_bytree=0.9538436675685811, learning_rate=0.05505176812345752, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9538436675685811, learning_rate=0.05505176812345752, max_depth=4, n_estimators=100, score=0.5593724440451604, total=   0.6s\n",
      "[CV] colsample_bytree=0.9168987340468555, learning_rate=0.08488943382129595, max_depth=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9168987340468555, learning_rate=0.08488943382129595, max_depth=2, n_estimators=200, score=0.4685970095190827, total=   0.7s\n",
      "[CV] colsample_bytree=0.9168987340468555, learning_rate=0.08488943382129595, max_depth=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    3.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9168987340468555, learning_rate=0.08488943382129595, max_depth=2, n_estimators=200, score=0.522386871294065, total=   0.7s\n",
      "[CV] colsample_bytree=0.9168987340468555, learning_rate=0.08488943382129595, max_depth=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    3.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9168987340468555, learning_rate=0.08488943382129595, max_depth=2, n_estimators=200, score=0.5256114218157519, total=   0.7s\n",
      "[CV] colsample_bytree=0.31990641183346374, learning_rate=0.04224378104873386, max_depth=4, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    4.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.31990641183346374, learning_rate=0.04224378104873386, max_depth=4, n_estimators=200, score=0.3883380401001336, total=   1.0s\n",
      "[CV] colsample_bytree=0.31990641183346374, learning_rate=0.04224378104873386, max_depth=4, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    5.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.31990641183346374, learning_rate=0.04224378104873386, max_depth=4, n_estimators=200, score=0.431159289308372, total=   1.0s\n",
      "[CV] colsample_bytree=0.31990641183346374, learning_rate=0.04224378104873386, max_depth=4, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    7.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.31990641183346374, learning_rate=0.04224378104873386, max_depth=4, n_estimators=200, score=0.4343214979405511, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    8.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    8.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.536533 using {'colsample_bytree': 0.9538436675685811, 'learning_rate': 0.05505176812345752, 'max_depth': 4, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "df_initial = pd.read_csv('pirates_of_caribbean.csv')\n",
    "for index, row in df_initial.iterrows():\n",
    "    if math.isnan(row['SPOSTMIN']):\n",
    "        df_initial.loc[index,'SPOSTMIN'] = df_initial.loc[index, 'SACTMIN']\n",
    "#     print(row['SPOSTMIN'], row['SACTMIN'])\n",
    "df_initial = df_initial.drop(columns=\"SACTMIN\")\n",
    "df_initial = df_initial[df_initial['SPOSTMIN'] != -999]\n",
    "df_initial['Month'] = df_initial.date.str.split('/').str[0]\n",
    "df_initial['Day'] = df_initial.date.str.split('/').str[1]\n",
    "df_initial['Year'] = df_initial.date.str.rsplit('/', 1).str[1]\n",
    "df_initial['Time_char'] = df_initial.datetime.str.split(' ').str[1]\n",
    "df_initial['Hour'] = df_initial['Time_char'].str.split(':').str[0]\n",
    "df_initial['Minute'] = df_initial['Time_char'].str.split(':').str[1]\n",
    "df_initial = df_initial.drop(columns=\"Time_char\")\n",
    "df_initial['Month'] = (df_initial['Month']).astype(int)\n",
    "df_initial['Day'] = (df_initial['Day']).astype(int)\n",
    "df_initial['Year'] = (df_initial['Year']).astype(int)\n",
    "df_initial['Hour'] = (df_initial['Hour']).astype(int)\n",
    "df_initial['Minute'] = (df_initial['Minute']).astype(int)\n",
    "df_y = df_initial['SPOSTMIN']\n",
    "label_encoder_DOW = LabelEncoder()\n",
    "DoW_feature = label_encoder_DOW.fit_transform(df_initial.DAYOFWEEK.iloc[:].values)\n",
    "# new_col = pd.Series(DoW_feature)\n",
    "df_initial['DayOfWeek'] = DoW_feature\n",
    "df_initial = df_initial.drop(columns=[\"DAYOFWEEK\", \"date\", \"datetime\", \"SPOSTMIN\"])\n",
    "random_seed = 5\n",
    "t_s = .20\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_initial, df_y, test_size = t_s, random_state = random_seed)\n",
    "param_grid = {'n_estimators': [100, 200, 300], #random int btwn 100 and 500 - removed\n",
    "              'learning_rate': stats.uniform(0.01, 0.08), #.01 + loc, range of .01+/-.08\n",
    "              'max_depth': [2, 4, 6, 8], #tree depths to check\n",
    "              'colsample_bytree': stats.uniform(0.3, 0.7) #btwn .1 and 1.0    \n",
    "}\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=random_seed)\n",
    "model = XGBRegressor(tree_method='gpu_hist')\n",
    "rand_search = RandomizedSearchCV(model, param_distributions = param_grid, scoring = 'explained_variance', n_iter = 3, verbose = 10, cv=kfold)\n",
    "rand_result = rand_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (rand_result.best_score_, rand_result.best_params_))\n",
    "best_XGB_estimator = rand_result.best_estimator_\n",
    "pickle.dump(best_XGB_estimator, open(\"xgb_pirates_of_caribbean.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] colsample_bytree=0.7229412082413382, learning_rate=0.017631665954581488, max_depth=6, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7229412082413382, learning_rate=0.017631665954581488, max_depth=6, n_estimators=100, score=0.37021405669197505, total=   1.6s\n",
      "[CV] colsample_bytree=0.7229412082413382, learning_rate=0.017631665954581488, max_depth=6, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7229412082413382, learning_rate=0.017631665954581488, max_depth=6, n_estimators=100, score=0.3668389652453722, total=   1.6s\n",
      "[CV] colsample_bytree=0.7229412082413382, learning_rate=0.017631665954581488, max_depth=6, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7229412082413382, learning_rate=0.017631665954581488, max_depth=6, n_estimators=100, score=0.36789752594988256, total=   1.6s\n",
      "[CV] colsample_bytree=0.443549253455096, learning_rate=0.04388167052079101, max_depth=8, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.443549253455096, learning_rate=0.04388167052079101, max_depth=8, n_estimators=300, score=0.4816051387700847, total=   8.7s\n",
      "[CV] colsample_bytree=0.443549253455096, learning_rate=0.04388167052079101, max_depth=8, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   13.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.443549253455096, learning_rate=0.04388167052079101, max_depth=8, n_estimators=300, score=0.48250434010467247, total=   8.7s\n",
      "[CV] colsample_bytree=0.443549253455096, learning_rate=0.04388167052079101, max_depth=8, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   22.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.443549253455096, learning_rate=0.04388167052079101, max_depth=8, n_estimators=300, score=0.48125146620199244, total=   8.8s\n",
      "[CV] colsample_bytree=0.7866774812377872, learning_rate=0.04462529486861672, max_depth=8, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   31.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7866774812377872, learning_rate=0.04462529486861672, max_depth=8, n_estimators=100, score=0.5500395960703122, total=   5.0s\n",
      "[CV] colsample_bytree=0.7866774812377872, learning_rate=0.04462529486861672, max_depth=8, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   36.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7866774812377872, learning_rate=0.04462529486861672, max_depth=8, n_estimators=100, score=0.5502636426450886, total=   5.0s\n",
      "[CV] colsample_bytree=0.7866774812377872, learning_rate=0.04462529486861672, max_depth=8, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   42.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7866774812377872, learning_rate=0.04462529486861672, max_depth=8, n_estimators=100, score=0.5537426824066967, total=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   47.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   47.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.551349 using {'colsample_bytree': 0.7866774812377872, 'learning_rate': 0.04462529486861672, 'max_depth': 8, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "df_initial = pd.read_csv('rock_n_rollercoaster.csv')\n",
    "for index, row in df_initial.iterrows():\n",
    "    if math.isnan(row['SPOSTMIN']):\n",
    "        df_initial.loc[index,'SPOSTMIN'] = df_initial.loc[index, 'SACTMIN']\n",
    "#     print(row['SPOSTMIN'], row['SACTMIN'])\n",
    "df_initial = df_initial.drop(columns=\"SACTMIN\")\n",
    "df_initial = df_initial[df_initial['SPOSTMIN'] != -999]\n",
    "df_initial['Month'] = df_initial.date.str.split('/').str[0]\n",
    "df_initial['Day'] = df_initial.date.str.split('/').str[1]\n",
    "df_initial['Year'] = df_initial.date.str.rsplit('/', 1).str[1]\n",
    "df_initial['Time_char'] = df_initial.datetime.str.split(' ').str[1]\n",
    "df_initial['Hour'] = df_initial['Time_char'].str.split(':').str[0]\n",
    "df_initial['Minute'] = df_initial['Time_char'].str.split(':').str[1]\n",
    "df_initial = df_initial.drop(columns=\"Time_char\")\n",
    "df_initial['Month'] = (df_initial['Month']).astype(int)\n",
    "df_initial['Day'] = (df_initial['Day']).astype(int)\n",
    "df_initial['Year'] = (df_initial['Year']).astype(int)\n",
    "df_initial['Hour'] = (df_initial['Hour']).astype(int)\n",
    "df_initial['Minute'] = (df_initial['Minute']).astype(int)\n",
    "df_y = df_initial['SPOSTMIN']\n",
    "label_encoder_DOW = LabelEncoder()\n",
    "DoW_feature = label_encoder_DOW.fit_transform(df_initial.DAYOFWEEK.iloc[:].values)\n",
    "# new_col = pd.Series(DoW_feature)\n",
    "df_initial['DayOfWeek'] = DoW_feature\n",
    "df_initial = df_initial.drop(columns=[\"DAYOFWEEK\", \"date\", \"datetime\", \"SPOSTMIN\"])\n",
    "random_seed = 5\n",
    "t_s = .20\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_initial, df_y, test_size = t_s, random_state = random_seed)\n",
    "param_grid = {'n_estimators': [100, 200, 300], #random int btwn 100 and 500 - removed\n",
    "              'learning_rate': stats.uniform(0.01, 0.08), #.01 + loc, range of .01+/-.08\n",
    "              'max_depth': [2, 4, 6, 8], #tree depths to check\n",
    "              'colsample_bytree': stats.uniform(0.3, 0.7) #btwn .1 and 1.0    \n",
    "}\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=random_seed)\n",
    "model = XGBRegressor(tree_method='gpu_hist')\n",
    "rand_search = RandomizedSearchCV(model, param_distributions = param_grid, scoring = 'explained_variance', n_iter = 3, verbose = 10, cv=kfold)\n",
    "rand_result = rand_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (rand_result.best_score_, rand_result.best_params_))\n",
    "best_XGB_estimator = rand_result.best_estimator_\n",
    "pickle.dump(best_XGB_estimator, open(\"xgb_rock_n_rollercoaster.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] colsample_bytree=0.300776927113, learning_rate=0.0472120868990769, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.300776927113, learning_rate=0.0472120868990769, max_depth=4, n_estimators=100, score=0.3117412597703185, total=   0.2s\n",
      "[CV] colsample_bytree=0.300776927113, learning_rate=0.0472120868990769, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.300776927113, learning_rate=0.0472120868990769, max_depth=4, n_estimators=100, score=0.3166569543566983, total=   0.2s\n",
      "[CV] colsample_bytree=0.300776927113, learning_rate=0.0472120868990769, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.300776927113, learning_rate=0.0472120868990769, max_depth=4, n_estimators=100, score=0.31723508813090084, total=   0.2s\n",
      "[CV] colsample_bytree=0.6569678654644897, learning_rate=0.08011830417509848, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.6569678654644897, learning_rate=0.08011830417509848, max_depth=4, n_estimators=100, score=0.651795078200759, total=   0.3s\n",
      "[CV] colsample_bytree=0.6569678654644897, learning_rate=0.08011830417509848, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.6569678654644897, learning_rate=0.08011830417509848, max_depth=4, n_estimators=100, score=0.64593146420809, total=   0.3s\n",
      "[CV] colsample_bytree=0.6569678654644897, learning_rate=0.08011830417509848, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.6569678654644897, learning_rate=0.08011830417509848, max_depth=4, n_estimators=100, score=0.6556578554016566, total=   0.3s\n",
      "[CV] colsample_bytree=0.3416092135935267, learning_rate=0.027342075160993948, max_depth=8, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    2.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.3416092135935267, learning_rate=0.027342075160993948, max_depth=8, n_estimators=300, score=0.6759867061162864, total=   5.2s\n",
      "[CV] colsample_bytree=0.3416092135935267, learning_rate=0.027342075160993948, max_depth=8, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    7.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.3416092135935267, learning_rate=0.027342075160993948, max_depth=8, n_estimators=300, score=0.6946859587648129, total=   5.1s\n",
      "[CV] colsample_bytree=0.3416092135935267, learning_rate=0.027342075160993948, max_depth=8, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   12.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.3416092135935267, learning_rate=0.027342075160993948, max_depth=8, n_estimators=300, score=0.695679051131108, total=   5.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   17.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   17.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.688783 using {'colsample_bytree': 0.3416092135935267, 'learning_rate': 0.027342075160993948, 'max_depth': 8, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "df_initial = pd.read_csv('slinky_dog.csv')\n",
    "for index, row in df_initial.iterrows():\n",
    "    if math.isnan(row['SPOSTMIN']):\n",
    "        df_initial.loc[index,'SPOSTMIN'] = df_initial.loc[index, 'SACTMIN']\n",
    "#     print(row['SPOSTMIN'], row['SACTMIN'])\n",
    "df_initial = df_initial.drop(columns=\"SACTMIN\")\n",
    "df_initial = df_initial[df_initial['SPOSTMIN'] != -999]\n",
    "df_initial['Month'] = df_initial.date.str.split('/').str[0]\n",
    "df_initial['Day'] = df_initial.date.str.split('/').str[1]\n",
    "df_initial['Year'] = df_initial.date.str.rsplit('/', 1).str[1]\n",
    "df_initial['Time_char'] = df_initial.datetime.str.split(' ').str[1]\n",
    "df_initial['Hour'] = df_initial['Time_char'].str.split(':').str[0]\n",
    "df_initial['Minute'] = df_initial['Time_char'].str.split(':').str[1]\n",
    "df_initial = df_initial.drop(columns=\"Time_char\")\n",
    "df_initial['Month'] = (df_initial['Month']).astype(int)\n",
    "df_initial['Day'] = (df_initial['Day']).astype(int)\n",
    "df_initial['Year'] = (df_initial['Year']).astype(int)\n",
    "df_initial['Hour'] = (df_initial['Hour']).astype(int)\n",
    "df_initial['Minute'] = (df_initial['Minute']).astype(int)\n",
    "df_y = df_initial['SPOSTMIN']\n",
    "label_encoder_DOW = LabelEncoder()\n",
    "DoW_feature = label_encoder_DOW.fit_transform(df_initial.DAYOFWEEK.iloc[:].values)\n",
    "# new_col = pd.Series(DoW_feature)\n",
    "df_initial['DayOfWeek'] = DoW_feature\n",
    "df_initial = df_initial.drop(columns=[\"DAYOFWEEK\", \"date\", \"datetime\", \"SPOSTMIN\"])\n",
    "random_seed = 5\n",
    "t_s = .20\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_initial, df_y, test_size = t_s, random_state = random_seed)\n",
    "param_grid = {'n_estimators': [100, 200, 300], #random int btwn 100 and 500 - removed\n",
    "              'learning_rate': stats.uniform(0.01, 0.08), #.01 + loc, range of .01+/-.08\n",
    "              'max_depth': [2, 4, 6, 8], #tree depths to check\n",
    "              'colsample_bytree': stats.uniform(0.3, 0.7) #btwn .1 and 1.0    \n",
    "}\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=random_seed)\n",
    "model = XGBRegressor(tree_method='gpu_hist')\n",
    "rand_search = RandomizedSearchCV(model, param_distributions = param_grid, scoring = 'explained_variance', n_iter = 3, verbose = 10, cv=kfold)\n",
    "rand_result = rand_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (rand_result.best_score_, rand_result.best_params_))\n",
    "best_XGB_estimator = rand_result.best_estimator_\n",
    "pickle.dump(best_XGB_estimator, open(\"xgb_slinky_dog.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] colsample_bytree=0.8867718295025033, learning_rate=0.014657561370748669, max_depth=2, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8867718295025033, learning_rate=0.014657561370748669, max_depth=2, n_estimators=300, score=0.36183954723485956, total=   1.0s\n",
      "[CV] colsample_bytree=0.8867718295025033, learning_rate=0.014657561370748669, max_depth=2, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8867718295025033, learning_rate=0.014657561370748669, max_depth=2, n_estimators=300, score=0.37332048783083926, total=   1.0s\n",
      "[CV] colsample_bytree=0.8867718295025033, learning_rate=0.014657561370748669, max_depth=2, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8867718295025033, learning_rate=0.014657561370748669, max_depth=2, n_estimators=300, score=0.37756722570053125, total=   1.1s\n",
      "[CV] colsample_bytree=0.9008746559435541, learning_rate=0.05551380174124687, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9008746559435541, learning_rate=0.05551380174124687, max_depth=4, n_estimators=100, score=0.4972547989717965, total=   0.6s\n",
      "[CV] colsample_bytree=0.9008746559435541, learning_rate=0.05551380174124687, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9008746559435541, learning_rate=0.05551380174124687, max_depth=4, n_estimators=100, score=0.5121032457558534, total=   0.6s\n",
      "[CV] colsample_bytree=0.9008746559435541, learning_rate=0.05551380174124687, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    4.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9008746559435541, learning_rate=0.05551380174124687, max_depth=4, n_estimators=100, score=0.5163734723389105, total=   0.6s\n",
      "[CV] colsample_bytree=0.7773943404320777, learning_rate=0.03182031225216541, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    5.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7773943404320777, learning_rate=0.03182031225216541, max_depth=4, n_estimators=100, score=0.43418297098666936, total=   0.6s\n",
      "[CV] colsample_bytree=0.7773943404320777, learning_rate=0.03182031225216541, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    6.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7773943404320777, learning_rate=0.03182031225216541, max_depth=4, n_estimators=100, score=0.44528924780548884, total=   0.6s\n",
      "[CV] colsample_bytree=0.7773943404320777, learning_rate=0.03182031225216541, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    7.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7773943404320777, learning_rate=0.03182031225216541, max_depth=4, n_estimators=100, score=0.45151921358614655, total=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    8.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    8.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.508577 using {'colsample_bytree': 0.9008746559435541, 'learning_rate': 0.05551380174124687, 'max_depth': 4, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "df_initial = pd.read_csv('soarin.csv')\n",
    "for index, row in df_initial.iterrows():\n",
    "    if math.isnan(row['SPOSTMIN']):\n",
    "        df_initial.loc[index,'SPOSTMIN'] = df_initial.loc[index, 'SACTMIN']\n",
    "#     print(row['SPOSTMIN'], row['SACTMIN'])\n",
    "df_initial = df_initial.drop(columns=\"SACTMIN\")\n",
    "df_initial = df_initial[df_initial['SPOSTMIN'] != -999]\n",
    "df_initial['Month'] = df_initial.date.str.split('/').str[0]\n",
    "df_initial['Day'] = df_initial.date.str.split('/').str[1]\n",
    "df_initial['Year'] = df_initial.date.str.rsplit('/', 1).str[1]\n",
    "df_initial['Time_char'] = df_initial.datetime.str.split(' ').str[1]\n",
    "df_initial['Hour'] = df_initial['Time_char'].str.split(':').str[0]\n",
    "df_initial['Minute'] = df_initial['Time_char'].str.split(':').str[1]\n",
    "df_initial = df_initial.drop(columns=\"Time_char\")\n",
    "df_initial['Month'] = (df_initial['Month']).astype(int)\n",
    "df_initial['Day'] = (df_initial['Day']).astype(int)\n",
    "df_initial['Year'] = (df_initial['Year']).astype(int)\n",
    "df_initial['Hour'] = (df_initial['Hour']).astype(int)\n",
    "df_initial['Minute'] = (df_initial['Minute']).astype(int)\n",
    "df_y = df_initial['SPOSTMIN']\n",
    "label_encoder_DOW = LabelEncoder()\n",
    "DoW_feature = label_encoder_DOW.fit_transform(df_initial.DAYOFWEEK.iloc[:].values)\n",
    "# new_col = pd.Series(DoW_feature)\n",
    "df_initial['DayOfWeek'] = DoW_feature\n",
    "df_initial = df_initial.drop(columns=[\"DAYOFWEEK\", \"date\", \"datetime\", \"SPOSTMIN\"])\n",
    "random_seed = 5\n",
    "t_s = .20\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_initial, df_y, test_size = t_s, random_state = random_seed)\n",
    "param_grid = {'n_estimators': [100, 200, 300], #random int btwn 100 and 500 - removed\n",
    "              'learning_rate': stats.uniform(0.01, 0.08), #.01 + loc, range of .01+/-.08\n",
    "              'max_depth': [2, 4, 6, 8], #tree depths to check\n",
    "              'colsample_bytree': stats.uniform(0.3, 0.7) #btwn .1 and 1.0    \n",
    "}\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=random_seed)\n",
    "model = XGBRegressor(tree_method='gpu_hist')\n",
    "rand_search = RandomizedSearchCV(model, param_distributions = param_grid, scoring = 'explained_variance', n_iter = 3, verbose = 10, cv=kfold)\n",
    "rand_result = rand_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (rand_result.best_score_, rand_result.best_params_))\n",
    "best_XGB_estimator = rand_result.best_estimator_\n",
    "pickle.dump(best_XGB_estimator, open(\"xgb_soarin.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] colsample_bytree=0.8276186193730097, learning_rate=0.010345523035463442, max_depth=4, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8276186193730097, learning_rate=0.010345523035463442, max_depth=4, n_estimators=200, score=0.4654945554105976, total=   1.2s\n",
      "[CV] colsample_bytree=0.8276186193730097, learning_rate=0.010345523035463442, max_depth=4, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8276186193730097, learning_rate=0.010345523035463442, max_depth=4, n_estimators=200, score=0.4715192586499225, total=   1.2s\n",
      "[CV] colsample_bytree=0.8276186193730097, learning_rate=0.010345523035463442, max_depth=4, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8276186193730097, learning_rate=0.010345523035463442, max_depth=4, n_estimators=200, score=0.4700572542453536, total=   1.2s\n",
      "[CV] colsample_bytree=0.9474689470015636, learning_rate=0.031893486261045406, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    4.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9474689470015636, learning_rate=0.031893486261045406, max_depth=4, n_estimators=100, score=0.5338982757681885, total=   0.6s\n",
      "[CV] colsample_bytree=0.9474689470015636, learning_rate=0.031893486261045406, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9474689470015636, learning_rate=0.031893486261045406, max_depth=4, n_estimators=100, score=0.5424877033901747, total=   0.6s\n",
      "[CV] colsample_bytree=0.9474689470015636, learning_rate=0.031893486261045406, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9474689470015636, learning_rate=0.031893486261045406, max_depth=4, n_estimators=100, score=0.5401822015287709, total=   0.6s\n",
      "[CV] colsample_bytree=0.7951321565675904, learning_rate=0.07110810933243497, max_depth=6, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    6.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7951321565675904, learning_rate=0.07110810933243497, max_depth=6, n_estimators=200, score=0.7000382387126445, total=   3.1s\n",
      "[CV] colsample_bytree=0.7951321565675904, learning_rate=0.07110810933243497, max_depth=6, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    9.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7951321565675904, learning_rate=0.07110810933243497, max_depth=6, n_estimators=200, score=0.7009169192189914, total=   3.1s\n",
      "[CV] colsample_bytree=0.7951321565675904, learning_rate=0.07110810933243497, max_depth=6, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   12.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7951321565675904, learning_rate=0.07110810933243497, max_depth=6, n_estimators=200, score=0.7003149359680536, total=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   16.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   16.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.700423 using {'colsample_bytree': 0.7951321565675904, 'learning_rate': 0.07110810933243497, 'max_depth': 6, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "df_initial = pd.read_csv('spaceship_earth.csv')\n",
    "for index, row in df_initial.iterrows():\n",
    "    if math.isnan(row['SPOSTMIN']):\n",
    "        df_initial.loc[index,'SPOSTMIN'] = df_initial.loc[index, 'SACTMIN']\n",
    "#     print(row['SPOSTMIN'], row['SACTMIN'])\n",
    "df_initial = df_initial.drop(columns=\"SACTMIN\")\n",
    "df_initial = df_initial[df_initial['SPOSTMIN'] != -999]\n",
    "df_initial['Month'] = df_initial.date.str.split('/').str[0]\n",
    "df_initial['Day'] = df_initial.date.str.split('/').str[1]\n",
    "df_initial['Year'] = df_initial.date.str.rsplit('/', 1).str[1]\n",
    "df_initial['Time_char'] = df_initial.datetime.str.split(' ').str[1]\n",
    "df_initial['Hour'] = df_initial['Time_char'].str.split(':').str[0]\n",
    "df_initial['Minute'] = df_initial['Time_char'].str.split(':').str[1]\n",
    "df_initial = df_initial.drop(columns=\"Time_char\")\n",
    "df_initial['Month'] = (df_initial['Month']).astype(int)\n",
    "df_initial['Day'] = (df_initial['Day']).astype(int)\n",
    "df_initial['Year'] = (df_initial['Year']).astype(int)\n",
    "df_initial['Hour'] = (df_initial['Hour']).astype(int)\n",
    "df_initial['Minute'] = (df_initial['Minute']).astype(int)\n",
    "df_y = df_initial['SPOSTMIN']\n",
    "label_encoder_DOW = LabelEncoder()\n",
    "DoW_feature = label_encoder_DOW.fit_transform(df_initial.DAYOFWEEK.iloc[:].values)\n",
    "# new_col = pd.Series(DoW_feature)\n",
    "df_initial['DayOfWeek'] = DoW_feature\n",
    "df_initial = df_initial.drop(columns=[\"DAYOFWEEK\", \"date\", \"datetime\", \"SPOSTMIN\"])\n",
    "random_seed = 5\n",
    "t_s = .20\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_initial, df_y, test_size = t_s, random_state = random_seed)\n",
    "param_grid = {'n_estimators': [100, 200, 300], #random int btwn 100 and 500 - removed\n",
    "              'learning_rate': stats.uniform(0.01, 0.08), #.01 + loc, range of .01+/-.08\n",
    "              'max_depth': [2, 4, 6, 8], #tree depths to check\n",
    "              'colsample_bytree': stats.uniform(0.3, 0.7) #btwn .1 and 1.0    \n",
    "}\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=random_seed)\n",
    "model = XGBRegressor(tree_method='gpu_hist')\n",
    "rand_search = RandomizedSearchCV(model, param_distributions = param_grid, scoring = 'explained_variance', n_iter = 3, verbose = 10, cv=kfold)\n",
    "rand_result = rand_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (rand_result.best_score_, rand_result.best_params_))\n",
    "best_XGB_estimator = rand_result.best_estimator_\n",
    "pickle.dump(best_XGB_estimator, open(\"xgb_spaceship_earth.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] colsample_bytree=0.9710119106581161, learning_rate=0.07147565132457223, max_depth=8, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9710119106581161, learning_rate=0.07147565132457223, max_depth=8, n_estimators=200, score=0.8069952723154302, total=  10.3s\n",
      "[CV] colsample_bytree=0.9710119106581161, learning_rate=0.07147565132457223, max_depth=8, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9710119106581161, learning_rate=0.07147565132457223, max_depth=8, n_estimators=200, score=0.8071799015668484, total=  10.3s\n",
      "[CV] colsample_bytree=0.9710119106581161, learning_rate=0.07147565132457223, max_depth=8, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   20.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9710119106581161, learning_rate=0.07147565132457223, max_depth=8, n_estimators=200, score=0.8048558029553516, total=  10.5s\n",
      "[CV] colsample_bytree=0.7839141070761564, learning_rate=0.06806845573905287, max_depth=6, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   31.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7839141070761564, learning_rate=0.06806845573905287, max_depth=6, n_estimators=200, score=0.7274864684533215, total=   3.1s\n",
      "[CV] colsample_bytree=0.7839141070761564, learning_rate=0.06806845573905287, max_depth=6, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   34.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7839141070761564, learning_rate=0.06806845573905287, max_depth=6, n_estimators=200, score=0.7284047783417895, total=   3.1s\n",
      "[CV] colsample_bytree=0.7839141070761564, learning_rate=0.06806845573905287, max_depth=6, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   38.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7839141070761564, learning_rate=0.06806845573905287, max_depth=6, n_estimators=200, score=0.7296086014427452, total=   3.1s\n",
      "[CV] colsample_bytree=0.560361210484058, learning_rate=0.04254563113176944, max_depth=4, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   41.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.560361210484058, learning_rate=0.04254563113176944, max_depth=4, n_estimators=200, score=0.5941058672259782, total=   1.2s\n",
      "[CV] colsample_bytree=0.560361210484058, learning_rate=0.04254563113176944, max_depth=4, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   42.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.560361210484058, learning_rate=0.04254563113176944, max_depth=4, n_estimators=200, score=0.5903252284031726, total=   1.2s\n",
      "[CV] colsample_bytree=0.560361210484058, learning_rate=0.04254563113176944, max_depth=4, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   44.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.560361210484058, learning_rate=0.04254563113176944, max_depth=4, n_estimators=200, score=0.5921290088796246, total=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   45.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   45.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.806344 using {'colsample_bytree': 0.9710119106581161, 'learning_rate': 0.07147565132457223, 'max_depth': 8, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "df_initial = pd.read_csv('splash_mountain.csv')\n",
    "for index, row in df_initial.iterrows():\n",
    "    if math.isnan(row['SPOSTMIN']):\n",
    "        df_initial.loc[index,'SPOSTMIN'] = df_initial.loc[index, 'SACTMIN']\n",
    "#     print(row['SPOSTMIN'], row['SACTMIN'])\n",
    "df_initial = df_initial.drop(columns=\"SACTMIN\")\n",
    "df_initial = df_initial[df_initial['SPOSTMIN'] != -999]\n",
    "df_initial['Month'] = df_initial.date.str.split('/').str[0]\n",
    "df_initial['Day'] = df_initial.date.str.split('/').str[1]\n",
    "df_initial['Year'] = df_initial.date.str.rsplit('/', 1).str[1]\n",
    "df_initial['Time_char'] = df_initial.datetime.str.split(' ').str[1]\n",
    "df_initial['Hour'] = df_initial['Time_char'].str.split(':').str[0]\n",
    "df_initial['Minute'] = df_initial['Time_char'].str.split(':').str[1]\n",
    "df_initial = df_initial.drop(columns=\"Time_char\")\n",
    "df_initial['Month'] = (df_initial['Month']).astype(int)\n",
    "df_initial['Day'] = (df_initial['Day']).astype(int)\n",
    "df_initial['Year'] = (df_initial['Year']).astype(int)\n",
    "df_initial['Hour'] = (df_initial['Hour']).astype(int)\n",
    "df_initial['Minute'] = (df_initial['Minute']).astype(int)\n",
    "df_y = df_initial['SPOSTMIN']\n",
    "label_encoder_DOW = LabelEncoder()\n",
    "DoW_feature = label_encoder_DOW.fit_transform(df_initial.DAYOFWEEK.iloc[:].values)\n",
    "# new_col = pd.Series(DoW_feature)\n",
    "df_initial['DayOfWeek'] = DoW_feature\n",
    "df_initial = df_initial.drop(columns=[\"DAYOFWEEK\", \"date\", \"datetime\", \"SPOSTMIN\"])\n",
    "random_seed = 5\n",
    "t_s = .20\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_initial, df_y, test_size = t_s, random_state = random_seed)\n",
    "param_grid = {'n_estimators': [100, 200, 300], #random int btwn 100 and 500 - removed\n",
    "              'learning_rate': stats.uniform(0.01, 0.08), #.01 + loc, range of .01+/-.08\n",
    "              'max_depth': [2, 4, 6, 8], #tree depths to check\n",
    "              'colsample_bytree': stats.uniform(0.3, 0.7) #btwn .1 and 1.0    \n",
    "}\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=random_seed)\n",
    "model = XGBRegressor(tree_method='gpu_hist')\n",
    "rand_search = RandomizedSearchCV(model, param_distributions = param_grid, scoring = 'explained_variance', n_iter = 3, verbose = 10, cv=kfold)\n",
    "rand_result = rand_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (rand_result.best_score_, rand_result.best_params_))\n",
    "best_XGB_estimator = rand_result.best_estimator_\n",
    "pickle.dump(best_XGB_estimator, open(\"xgb_splash_mountain.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] colsample_bytree=0.5941031901820354, learning_rate=0.0545130983127397, max_depth=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.5941031901820354, learning_rate=0.0545130983127397, max_depth=2, n_estimators=200, score=0.3805751168607082, total=   1.2s\n",
      "[CV] colsample_bytree=0.5941031901820354, learning_rate=0.0545130983127397, max_depth=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.5941031901820354, learning_rate=0.0545130983127397, max_depth=2, n_estimators=200, score=0.38468119179617455, total=   0.7s\n",
      "[CV] colsample_bytree=0.5941031901820354, learning_rate=0.0545130983127397, max_depth=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.5941031901820354, learning_rate=0.0545130983127397, max_depth=2, n_estimators=200, score=0.040859381778227566, total=   0.7s\n",
      "[CV] colsample_bytree=0.5184183872046262, learning_rate=0.025471527483897943, max_depth=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.5184183872046262, learning_rate=0.025471527483897943, max_depth=2, n_estimators=200, score=0.32291078729568123, total=   0.7s\n",
      "[CV] colsample_bytree=0.5184183872046262, learning_rate=0.025471527483897943, max_depth=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    3.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.5184183872046262, learning_rate=0.025471527483897943, max_depth=2, n_estimators=200, score=0.32471393749165733, total=   0.7s\n",
      "[CV] colsample_bytree=0.5184183872046262, learning_rate=0.025471527483897943, max_depth=2, n_estimators=200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    4.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.5184183872046262, learning_rate=0.025471527483897943, max_depth=2, n_estimators=200, score=0.034864724329228935, total=   0.7s\n",
      "[CV] colsample_bytree=0.9748802637447009, learning_rate=0.05592198956104434, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    5.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9748802637447009, learning_rate=0.05592198956104434, max_depth=4, n_estimators=100, score=0.49648408350135853, total=   0.6s\n",
      "[CV] colsample_bytree=0.9748802637447009, learning_rate=0.05592198956104434, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    6.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9748802637447009, learning_rate=0.05592198956104434, max_depth=4, n_estimators=100, score=0.5012972881772639, total=   0.6s\n",
      "[CV] colsample_bytree=0.9748802637447009, learning_rate=0.05592198956104434, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    6.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9748802637447009, learning_rate=0.05592198956104434, max_depth=4, n_estimators=100, score=0.053884468239179584, total=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    7.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    7.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.350555 using {'colsample_bytree': 0.9748802637447009, 'learning_rate': 0.05592198956104434, 'max_depth': 4, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "df_initial = pd.read_csv('toy_story_mania.csv')\n",
    "for index, row in df_initial.iterrows():\n",
    "    if math.isnan(row['SPOSTMIN']):\n",
    "        df_initial.loc[index,'SPOSTMIN'] = df_initial.loc[index, 'SACTMIN']\n",
    "#     print(row['SPOSTMIN'], row['SACTMIN'])\n",
    "df_initial = df_initial.drop(columns=\"SACTMIN\")\n",
    "df_initial = df_initial[df_initial['SPOSTMIN'] != -999]\n",
    "df_initial['Month'] = df_initial.date.str.split('/').str[0]\n",
    "df_initial['Day'] = df_initial.date.str.split('/').str[1]\n",
    "df_initial['Year'] = df_initial.date.str.rsplit('/', 1).str[1]\n",
    "df_initial['Time_char'] = df_initial.datetime.str.split(' ').str[1]\n",
    "df_initial['Hour'] = df_initial['Time_char'].str.split(':').str[0]\n",
    "df_initial['Minute'] = df_initial['Time_char'].str.split(':').str[1]\n",
    "df_initial = df_initial.drop(columns=\"Time_char\")\n",
    "df_initial['Month'] = (df_initial['Month']).astype(int)\n",
    "df_initial['Day'] = (df_initial['Day']).astype(int)\n",
    "df_initial['Year'] = (df_initial['Year']).astype(int)\n",
    "df_initial['Hour'] = (df_initial['Hour']).astype(int)\n",
    "df_initial['Minute'] = (df_initial['Minute']).astype(int)\n",
    "df_y = df_initial['SPOSTMIN']\n",
    "label_encoder_DOW = LabelEncoder()\n",
    "DoW_feature = label_encoder_DOW.fit_transform(df_initial.DAYOFWEEK.iloc[:].values)\n",
    "# new_col = pd.Series(DoW_feature)\n",
    "df_initial['DayOfWeek'] = DoW_feature\n",
    "df_initial = df_initial.drop(columns=[\"DAYOFWEEK\", \"date\", \"datetime\", \"SPOSTMIN\"])\n",
    "random_seed = 5\n",
    "t_s = .20\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_initial, df_y, test_size = t_s, random_state = random_seed)\n",
    "param_grid = {'n_estimators': [100, 200, 300], #random int btwn 100 and 500 - removed\n",
    "              'learning_rate': stats.uniform(0.01, 0.08), #.01 + loc, range of .01+/-.08\n",
    "              'max_depth': [2, 4, 6, 8], #tree depths to check\n",
    "              'colsample_bytree': stats.uniform(0.3, 0.7) #btwn .1 and 1.0    \n",
    "}\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=random_seed)\n",
    "model = XGBRegressor(tree_method='gpu_hist')\n",
    "rand_search = RandomizedSearchCV(model, param_distributions = param_grid, scoring = 'explained_variance', n_iter = 3, verbose = 10, cv=kfold)\n",
    "rand_result = rand_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (rand_result.best_score_, rand_result.best_params_))\n",
    "best_XGB_estimator = rand_result.best_estimator_\n",
    "pickle.dump(best_XGB_estimator, open(\"xgb_toy_story_mania.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
